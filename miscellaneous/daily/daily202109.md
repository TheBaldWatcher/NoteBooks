

[toc]

# OKR

## week 39——pre_week

* 上周工作
  * logreplay：
    * 适配trpc v0.8：有些配置以前用的默认值；现在不设置会导致一些问题（redis序列化失败、logreplay不上报等）
    * 整理代码、调整单测，提一版MR，已包含主要改动。单测代码还需继续调整。
    * 新正排索引：fix 由于多环境路由导致的录制问题；关闭动态索引的cache（之前只关掉了非动态）；似乎正排索引FlexBuffer比较特殊，在redis的反序列化时会出错，排查中。
  * 新模型特征：再次check user侧特征。Session有30%diff，目前看是redis返回Nil。但diff和为Nil比例为何这么大，待进一步解释。

* 08/27快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 中期：了解DAG、依赖图/计算图——并发配置化、Cpu亲和性/false share

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * 体检

  * 总结：

    * logreplay 
      * 解决redis序列化/反序列化
      * 测试环境流水线已ok
    * 特征：session 30%待查

  * 细则：

    * 09:00 进度
    * logreplay
      * 16:14 fix redis反序列化的问题
      * 20:39 似乎可以回放上了，但是偶尔会失败，有一次是record的user为空；另外，批量回放很容易超时——似乎是log相关，换成非gdb版本就好了
      * 21:46 批量录制有问题，pop的log会突然不刷
      * 记得配一下diff策略、目前在粗排代码里进行id排序
      * 写一下wiki
      * 23:10 似乎调通了，整理代码，并准备在hongfendong.coarse_ranking上测一下
    * 特征
      * session待查
* 08/31快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 中期：了解DAG、依赖图/计算图——并发配置化、Cpu亲和性/false share

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * 体检

  * 总结：

    * logreplay 
      * 在replay环境上莫名失败
    * 特征
      * 在线log复现了问题，似乎是history index导致的。排查中

  * 细则：

    * 09:00 进度
    * logreplay
      * 在replay环境上莫名地回放失败，问问adhuang
    * 特征
      * 11:55 准备跑下debug链路
      * 准备了debug链路，跑了下：key无diff，redis返回值有/无值，diff比例很低189/4158=4.5%
      * 发现是history index的差异，排查中。index 的 key diff很小
* 09/01快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 中期：了解DAG、依赖图/计算图——并发配置化、Cpu亲和性/false share

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * 体检

  * 总结：

    * Logreplay: 回放失败时超时引起的，似乎是pre的logreplay，5s+
    * 特征：
      * diff是因为历史索引ranking改了个查询参数，粗排没有对齐。
      * 明天等mengghu和kalowang好了之后起实验

  * 细则：

    * 09:00 进度
    * logreplay 
      - 回放数据处理失败似乎是超时引起的，5s+
    * 特征
      - 发现diff是由于ranking代码更新，更改了历史索引的Mode，从DOCINFO改为了DOCINFO_DICT_INDEPENDENT
      - 12:16 开始落日志，准备对比diff
      - 17:17 还是有8%diff。考虑到ranking线上268台，coarse ranking130台，调小50%流量，再录1小时
        - diff 7%，基本可用
* 09/02快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 中期：了解DAG、依赖图/计算图——并发配置化、Cpu亲和性/false share

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * 体检

  * 总结：

    * Logreplay: 
      * 数据包过大，20-40M，加上跨机房传输，导致回放超时。先用同机房（深圳）看看能否规避问题。另外让adhuang评估下是否能放宽超时+下调qps
    * 特征：
      * 准备起实验，准备环境

  * 细则：

    * 09:00 进度
    * logreplay
      * GetAspects 4.8s
      * 由于数据过大，20-40M，导致耗时过长，被平台判定为超时。adhuang那边评估下是否能放宽超时、降低qps为小数
      * 由于samuelcui的环境是天津机器，和logreplay平台通信时出现了跨机房。让samuelcui试试深圳环境，看看能否继续调试流水线
    * 新模型
      * 准备起实验
        * experiment_base2.coarse_ranking
        * experiment_test5.coarse_ranking
        * experiment_test4.coarse_ranking
    * 下半年的okr
* 09/03快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * okr

  * 总结：

    * Logreplay: 
      * 数据包过大，20-40M，加上跨机房传输，导致回放超时。先用同机房（深圳）看看能否规避问题。另外让adhuang评估下是否能放宽超时+下调qps
    * 特征：
      * 准备起实验，准备环境

  * 细则：

    * 10:00 进度
    * 特征：
      * 10:08 调试实验环境
      * 19:38 起实验
    * Logreplay:
      * 15:31 调整完一版单测，跑跑MR流水线看看。另外看是看看samuelcui说的流水线依然不行的问题
      * 手动回放能跑过，让samuelcui再试一下
      * MR已发大群。继续改MR流水线

## week 40

* 09/06快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * okr

  * 总结：

    * Logreplay: 
      * 跟进logreplay回放超时、后续拉个会
      * 序列化MR待提交
    * 特征：
      * 实验负向，未定位

  * 细则：

    * 11:00 进度
    * 实验负向
      * 怀疑的点：线上流量包含了推荐频道；user版本不一样；~~配置开在了联合层~~
    * logreplay 
      * 流水线
        * 先按1条进行调试，看看能否解决
        * adhuang看看aspect
        * 我试试压缩
      * MR
        * 解决rerank的编译问题，单测覆盖率不够，添加中
      * 序列化
* 09/07快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * okr

  * 总结：

    * Logreplay: 
      * 跟进logreplay回放超时、后续拉个会
      * 序列化MR——先发出来，单测待补
      * 尝试gzip压缩——耗时1.3s，压缩至35%左右，似乎不解决问题，且回放出错，估计http得改什么地方
    * 特征：
      * 实验负向，未定位。切回索引后，再跑一段时间看看

  * 细则：

    * 10:00 进度
* 09/08快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * okr

  * 总结：

    * Logreplay: 
      * 跟进logreplay回放超时、后续拉个会——感觉adhuang有点掉链子，一直没进展
      * 序列化MR——根据CR意见修改下，准备合入
      * 尝试gzip压缩——压缩耗时1.5s，解压0.5s，压缩至35-50%。大概收益2s，缓解但不解决问题
    * 特征：
      * 再积累一天数据，目前微正

  * 细则：

    * 10:00 进度
    * trpc MR
    * 调试压缩，压缩30-50%，压缩耗时1.5，解压耗时0.5
* 09/09 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * okr

  * 总结：

    * Logreplay: 
      * 查多线程问题
      * trpc MR已合入
    * 特征：
      * 

  * 细则：

    * 10:00 进度
    * logreplay
      * 11:18 似乎aspect数据有问题，有些字段缺失
      * 15:41 似乎是多线程问题，加mutex后全成功
      * 20:12 下午的代码总找不到具体哪有冲突，总有1个数据是乱的。mutex挪位置挪来挪去编译出错了，出core，堆栈是错的。clean之后build在poster上加了个mutex，回放51/51成功
* 09/10 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * okr

  * 总结：

    * Logreplay: 
      * 已合入astra master。不过rebase后，有两路没有录制下游，分别是新item redis；以及浩东的模型召回。模型召回似乎有随机性，待确认
    * 特征：
      * 又跑了下一致性，user特征diff没有问题
    * trpc set
      * 调试了一下，下周继续

  * 细则：
  
    * 10:00 进度
    * 14:55 实验跑不平，准备再落一下user 特征对一下看看
    * 19:26 下午落的日志，由于是debug级别，性能太差，和网络相关的特征diff过高，没有参考性。重编了一下，error级别开始罗日志

##week 41

* 1、logreplay-redis序列化/反序列化：已合入trpc master
  2、logreplay-cpp-sdk：添加gzip压缩，优化回放耗时；另外：似乎有多线程问题，拿到的aspect数据被写乱，导致回放数据丢失，比例很高；在post请求拿数据时加锁，可以大幅降低这个比例，至3%。但未完全解决。不太好定位到问题，暂时作为长期观察项，后续再调整；
  3、logreplay-astra MR：根据CR意见修改、解决conflict问题，已于周五合入master。不过master最近有改动，新增模型召回，没有录上，需要再调整一下
  4、新模型：起实验并跟进。观察实验效果中。总体来说不够正向。
  5、了解并支持trpc set路由需求，下周将用这个需求过一下logreplay链路

  下周计划：
  1、跟进模型小流量实验
  2、trpc set路由

* 09/13 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * okr
  * 总结：

    * 特征：
    * trpc set
      * 联调通，修改context，代码待提MR，需快点解决logreplay rebase后的回放失败问题
  * 细则：

    * 10:30 进度
    * Trpc set 路由
      * 11:41 play-粗排-召回联调通
      * 联调：
        * 15:28 和trigger联调完成，符合预期。另外，如果配了set_name但是下游trigger没有开启set，则是配置的锅
        * play那边的同学在参加iCode，晚饭后联调
        * 补单测
        * 22:25 联调——修改context而不是option
  * 09/14 快速的提升工程素养，和团队一起将粗排建设成一流水平

    * 长期：core guide、gmock，bazel、hana

    * 低优先级

      * 香港保险、作业
      * 股票、安居、居住证
      * should report的实现？
      * 周末：攀岩、消防绳、体检

    * 任务队列：深度召回

      * deep retrieval https://arxiv.org/abs/2007.07203
        TDM https://zhuanlan.zhihu.com/p/78941783
      * 会议纪要怎么弄
      * okr

    * 总结：

      * 特征：
        * 效果看起来不错，明天看看能否上线
      * trpc set
        * 联调通，修改context，代码待提MR，需快点解决logreplay rebase后的回放失败问题
        * logreplay rebase后的录制问题已解，并合到master。自测环境ok，但是samuelcui流水线说录制不到数据，待查
        * 晚上发现线上有耗时问题，可能会影响明天发布，问问能否通过联合层实验来调。——另外，看代码似乎是我把tcmalloc加回来导致的

    * 细则：

      * 10:00 进度

* 09/15 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * okr

  * 总结：

    * 特征：
      * 邮件已发，审批中
    * trpc set
      * set路由MR已合入并全量——中间有波动，似乎是有2.5%流量打的老ons
    * logreplay
      * 回放又开始失败了，问题待查

  * 细则：

    * 10:00 进度
    * 特征上线
    * set 路由
      * 14:25 MR已发
      * 17:39 已合入，并开始编译镜像
      * CheckAndSetCalleeSet log刷屏，明天改掉
    * logreplay
      * 录制数据为空
      * 改了下多环境路由，能有数据，但是粗排分一直为-100
      * 粗排分为-100是由于user emb的多环境路由问题；目前回放失败

* 09/16 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * okr

  * 总结：

    * 特征：评估中
    * trpc set
      * 小实验环境追基线后，配置有些问题，导致周四22点至周五16点数据不可用
    * logreplay
      * 回放又开始失败了，问题待查

  * 细则：

    * 13:55 进度。上午医院看病
    * 下午更新4路实验环境，追基线代码+set发布
    * 周五请假——4路实验环境中有3路配置有问题，拿不到索引信息，已修正。

* 09/18 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * okr

  * 总结：

    * 特征：
    * trpc set
    * logreplay

  * 细则：

    * 11:00 进度。上午医院看病
    * 召回set路由
      * test1环境镜像有问题，需重新发布
      * 似乎说有些set流量很低，待查——test1环境打过去的流量
    * logreplay环境需要更新set 路由
    * Logreplay:
      * 目前没有["data"]，但是每次打log的时候，response打印出来会变，甚至连续打印也是这样，copy也是这样。

## week 42

* 本周工作：
  1、logreplay astra代码在合入时，有其他粗排MR也在合入，这些MR的下游没有录制上。已更新相关代码并合入
  2、logreplay：之前拿aspect数据是乱的，加锁后，频率大幅降低。但本周合入后，又出现了，且比例很高，影响到流水线的使用。看来还是得完全解决才行，可能会比较耗时间。
  2、trpc set路由：召回主干开发需要粗排这边支持按set访问召回，即set路由。已联调通并全量。并更新小流量环境的代码。
  3、新特征模型小流量：小流量环境在追基线代码时，由于漏掉了部分下游服务的配置，导致这部分下游服务访问不同（多环境路由问题）。影响16-17日

  下周计划：
  1、跟进新特征模型小流量实验
  2、debug logreplay aspect数据乱掉的问题

* 09/22 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * okr

  * 总结：

    * 特征
    * logreplay
      * fix doRequest的生命周期问题；绕过rapidjson的array::Size问题。目前怀疑有部分下游没录上

  * 细则：

    * 10:45 进度。
    * logreplay
      * 17:22 doRequest在解析rapidjson时，用了个intu接口，导致生命周期有问题。fix后，发现拿不到回放数据，debug中。
      * 19:29 GetArray拿到的对象，其Size为0，导致for循环进不去。目前用ranged-for绕开。——从完全没结果，到有结果，但torank、norank长度不一致：怀疑部分请求没录上

* 09/23 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * okr

  * 总结：

    * 特征
      * 明天发MR准备推全
    * logreplay
      * 非模型召回无diff、怀疑item redis有diff、PbInvoke真实请求失败时不会进行mock

  * 细则：

    * logreplay
      * 怀疑非模型召回的trigger有diff——先看非模型召回的，没有diff
      * 怀疑item redis有diff
      * 查出pbinvoke在真实请求失败时，会导致mock数据改写不上的问题
    * set路由
      * 有非set的流量打到召回：好像线上没有配set路由，更新配置重启下看看
      * 有个kalowang的测试环境没有同步

* 09/24 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * okr

  * 总结：

    * 特征
      * 新特征MR、推全、开反转实验。另外和honghao确认下多环境路由
    * logreplay
      * 似乎trigger就不一致，待查

  * 细则：

    * logreplay
    * 特征
      * 整理代码，发MR
      * 推全
      * 反转实验服务地址配错

## week 43

* 09/26 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * okr
  * 总结：

    * 特征
    * logreplay
      * 截断前的sort需再按id排下需，避免进qouta的diff
      * trpc的MR
      * 仍有偶现diff，5%左右，有些是稳定的（再次回放依然失败），有些不稳定（再次回放无diff）
  * 细则：
  * 11:30 进度
  * rapidjson Size？具体是啥原因
  * logreplay
    * 15:41 diff有部分原因是相同粗排分，sort后顺序不定，导致截断有diff。修改后，好了很多；另外把no rank的coarse_ranking_score加黑名单，不然可能是乱码。但偶尔no_rank会有value/array-len不一致，待查
    * 原来的召回已经对齐了，但是开启模型召回后，有diff，2/10。
    * trpc的MR已发——失败时由于没有SetResponse导致不替换mock
    * 存在部分请求，5%，似乎to rank结果错位了
  * user emb似乎变得很大？！后续待查。
* 09/27 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * okr
  * 总结：

    * logreplay
      * 同一个key出现多条记录——一方面是模型召回的user、另外就是item redis分包（某路召回返回50个相同doc）
  * 细则：
    * logreplay
      * user emb有diff，click sequence看上去是record时101，但是特征却被设置了
        * 是因为有两个地方访问了同一个下游服务，logreplay的key都是同一个。其中一个成功，一个失败。回放时，数据乱掉，可能出现两个都成功或者两个都失败
        * 主要是模型召回那边的；另外，item redis也存在分包后，相同的情况（比如某一路召回返回了50个相同id）
      * 先调previous index
    * 其他
      * 似乎历史索引的field没有，但之前一致性又是ok的，待查
        * field为空时，是返回所有字段
* 09/28 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * okr
  * 总结：

    * logreplay
      * index真实请求失败时，不会上报mock数据，需要fix
      * user emb相同请求、召回内去重
      * 先调previous index
  * 细则：
    * 09:55 进度&邮件
    * logreplay
      * 先调previous index
      * user emb的video和non video有可能相等，需要加下判断
      * 每个召回内部做了去重
      * index失败时，resp是空的，但ConstructRpcData会认为data.data为空是失败，需要fix
* 09/29快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * 会议纪要怎么弄
    * okr
  * 总结：

    * logreplay
      * 对重复的ons去重
      * 模型召回有偶现diff，能拿到数据但是parse成pb失败
    * 插件会议：理一个方案出来
  * 细则：
    * 09:55 进度&邮件
    * logreplay
      * 13:15 fix: `if (!redis_cache) DoRedisLookup(server_context, redis_cache, doc_extends);`
      * 14: 25 已确认，previous index的已回放100、200条无diff
      * 15: 16 有重复的trigger，去重下
      * 仍有偶现diff，但很少（2/239）。看上去是模型召回的，能拿到数据，但是parse成pb出错
    * 插件升级
      * 16: 00会议
        * 现在的发布流程，开关项如何测的？
        * logreplay
          * 只能测完全相同的请求，新feature要人工diff；
          * 随机性、随机值、cache、set_time；
          * 会有多次、相同的下游请求么？
          * 代码有侵入性（无重复下游、透传server context、多环境路：测试、小流量环境）
        * 如何搭个测试环境，有没有什么坑，trpc配置用线上的？从哪copy流量
        * 痛点——节后给方案
          * 第一步，接入logreplay
          * 整个发布流程的规范——flags的组合？
          * 召回 detools脚本：开发机bin传到测试环境
          * 预发布环境、高中低用户按比例，抽10%。计算资源也按比例设计
* 09/30快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
    * 插件：方案
  * 总结：

    * logreplay
      * 
  * 细则：
    * 09:35 进度&邮件
    * logreplay
      * redis_proxy_wrapper  all.news_new_cat_profile.ssdb.com
      * 17:51 还是有偶现diff。但量级很少。另外，感觉需要过段时间再check下，以排除潜在的时间因素。目前awk对了下漏斗，在无diff的记录中，漏斗是完全相同的。
      * 10/1: 截断过滤有diff，flag、need calculate等字段
      * 10/5: 实在是太难复现了，很耗时，差不多要1小时
        * 之前的to_rank xxx过滤条件有问题，实际上，已经有diff了，但是打印是加了一步sort操作，导致以为是后面的操作有的diff。（在一个子函数调用中打log发现二者顺序不一致，才发现了这个问题）。更正后，目前定位到的位置是第4步有diff：按doc score+id排序。发现有多个doc是同样的doc、不同的分数，怀疑和这个有关。分数不一样是因为索引没查到，ChooseUserEmb导致的。
      * 10/6 使用stable sort
        * 13:16 回放330 ok
        * 14:17 还是不行
        * 15:27 发现一个可疑点：RandomProbItems用了随机数
        * 18:24 现在发现索引有diff……。目前看是新索引，但似乎没有mock error的log
      * 10/7 发现有两路会返回完全相同的doc……
        * trpc.news_top.svswing_recaller.httpTriggerNewsrecal qqnews.news_top.wxland_int_icf_swing_trigger
        * 目前有重复的ons、不同ons返回相同doc、单个ons返回多个重复的doc，直接对所有doc去重吧，并且关闭多线程，避免去重顺序的问题

## week 44

* 上周工作
  主要是查logreplay 偶现diff。主要是对同一个下游的相同请求出现了多次，hash得到的key是同一个，回放时按key查找，难以区分哪一个对应哪一个（比如一个成功，一个失败）。解决办法是要么对请求去重、要么想办法在hash时得到不同的key:
  1、sort改为stable_sort，避免排序时的顺序不确定问题
  2、重复下游调用：模型召回、非模型召回有部分代码是相同的。改了下hash使用的字段，使其key不一样
  3、重复下游调用：user需要按图文和视频分别去取embedding，但图文和视频特征有可能是完全一样的，导致蜕化成重复的请求。加了个判断，重复时只查一次
  4、重复下游调用：召回有重复的ons导致重复的doc、不同ons返回完全一样的doc、某一个ons返回重复的同一篇doc。这都导致后续查item embedding、查索引时，分包后会出现同样下游调用。目前打算对文章在一开始就去重（不过这会导致文章归并的逻辑测不到，大概10%）。
  5、随机数：调性过滤有个地方用到了随机数。设置了下seed，避免随机性。（调性过滤之前是不是发邮件说下掉了么？）

  下周计划：
  1、logreplay 偶现diff
  2、支持插件

* 10/08 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
    * 插件：方案
  * 总结：

    * logreplay
      * 似乎去重+串行可用，但是似乎适配trpc新版后，出现core，确认中
    * 插件
      * 给了下排期，从下周开始
  * 细则：
    * 10:30 进度&邮件
    * logreplay
      * 11:27 rebase后，需要适配下新的trpc代码: object_pool
      * 15:35 有core。晚上回放似乎没有了，但是整理代码push到git上后，又出现了，是不是trpc版本问题？
    * 插件
      * 给了下排期
      * 2、devops流程自动化。 -- 宏峰节后第一天详细设计和排期。
        a、小包小流量操作效率提升 及LogReplay流程建立（优先级低）。
        b、大包小流量机制、压测机制（按用户包比例）建立，目前是没有。
        c、epc流程机制引入，指标逐步提升避免一刀切。
        d、整体devops流程Demo产出
        e、大包功能测试，这里可以先想想（优先级低）。

* 10/09 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
    * 插件：方案
  * 总结：

    * logreplay
      * 测试环境、灿哥环境已经ok。目前是串行的，打算看看能否改回并行。
    * 插件
  * 细则：
    * 10:00 进度&邮件
    * logreplay
      * core的问题是因为切换了Object pool之后，对生命周期有了要求。改成leak接口后，不再有core。进一步和yuyanshi讨论了一下，感觉可以不用pool。因此先注释掉相关代码
      * 在自测环境上，回放500、717条无diff；代码上传后，在testing record/replay环境上，回放402条无diff

* 10/11 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
    * 插件：方案
  * 总结：

    * logreplay
      * 想优雅地传些信息进去差异化key，发现通过AddReqTransInfo不行：redis没有实现，问问lioncfliu
    * 插件——大包测试环境，作为预发布环境：快速暴露问题，方便定位小包谁有问题
  * 细则：
    * 10:00 进度&邮件
    * 改代码
    * Redis没有实现SetKVInfo，导致透传信息穿不进去

* 10/12 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
  * 总结：

    * logreplay：完善代码，透传信息给logreplay：
      * 完善trpc redis SetKvInfo
      * 提searchclient的MR并根据CR修改，已合入trpc_up分支
      * 提astra MR，单测待完善
    * 插件
      * 小包环境->5%预发环境->95%正式环境
      * Jenkins能否复用到123流水线
  * 细则：
    * 10:30 进度&邮件
    * 组会
      * 消重——改到真实下发，现在是计算处
        * 不敢重算
        * 加算，时间来不及，
      * 95%  5% 实验。比例压测环境，5%灰度环境，95%正式环境。每日压测5%->95%这一步
      * debug tool、小包
      * Jenkins - 123流水线

* 10/13 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
  * 总结：

    * logreplay
      * 整理单测
      * 另外和zhipengfan聊了一下
    * 插件
      * 开会，过kexing的方案
  * 细则：
    * 10:30 进度&邮件
    * 组会
      * 7.30-8,9,10 12点时间？？？
      * 模型稳定性：小时级劣于batch——号外影响，上1小时预估下一小时并不一定理想
      * 模型训练1小时-1.5小时。主要是venus离线任务抽风，无量很少抽风。
      * 模型抽风会影响4、5个点，dau7左右
      * 特殊业务需求，要求能快速兼容到；快速对所有流量都生效
      * 有些东西必须要大流量，且分步放，避免aa
        * 小包->5%->95%**带开关**，逐渐放量。开关关闭时，不能影响到主干
        * 压测时，不能开实验，不能改实验参数。所有设置在压测开始前设置好

* 10/14快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
  * 总结：

    * logreplay
      * 整理单测
    * 插件
      * 开会，过kexing的方案
  * 细则：
    * 10:15 进度&邮件
    * 其他
      * logreplay 14:00 整理单测，解决rerank、ranking、trigger的编译问题，已push上去，低优
      * set路由 log doc size已上传分支
      * item feature extractor已上传分支
    * 插件
      * 讨论了trigger接入tab分流的实现：目前打算复用Recommend服务，多开个接口出来，trigger请求两次。假定该接口为Func：
        * 请求Func接口，判断是否是tab实验？
          * 若是：则获取tab配置，依次查询profile、recall、ranking、rerank等配置的ons，若冲突则返回空
            * 若为polaris名？
            * 若为ons名？
            * 若为ip port？
          * 若非：
            * 则返回空？

* 10/15快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
  * 总结：

    * logreplay
    * 插件
      * 开会，过kexing的方案
  * 细则：
    * 10:15 进度&邮件
    * 插件
      * 下午发下MR、时间规划
      * 17:15 先发trigger的 MR
        * 加一个放回的逻辑
      * 周六
        * tab分流需要开在单层，多层域上做不了：多层域代表层域间独立，但是服务地址不是独立的
        * 19:05 brpc curl能拿到实验配置
        * todo 
          * qps优化
          * 加个容错：如果polaris配在了多层域，不使用——todo，等周一回来问下tab helper
          * proto传输

## week 45

* 10/18快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
  * 总结：

    * logreplay
    * 插件
      * 只查一次tab，避免查两次有diff。brpc RS开发完，验证中
  * 细则：
    * 10:15 进度&邮件
    * 插件
      * 只查一次tab：调整brpc RS，透传tab信息，并在有tab信息时略过查询。Recommend接口待验证，GetPolaris接口已符合预期
      * 587bb933.news_rs.wxplugin_trigger.sz101889  联调
      * 587bb933.news_rs.wxplugin_trigger.sz101875 联调-下游brpc rs

* 10/19快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
  * 总结：

    * logreplay
    * 插件
      * 调试trigger：调试ip port直连tab透传符合预期、测试环境验证了下分包
  * 细则：
    * 10:40 进度&邮件

* 10/20快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
  * 总结：

    * logreplay
    * 插件
      * 创建测试环境，trigger+rs + rs_baseline。调试可兴的clear queue参数
  * 细则：
    * 10:40 进度&邮件
    * 插件
      * 15:31 已部署rs到新的测试/正式环境。并能curl通。trigger昨晚联调节点已被123-k8s重启。发布到587bb933.news_rs.wxplugin_trigger.sz101984上继续联调

* 10/21 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
  * 总结：

    * logreplay
    * 插件
      * 按fesun建议：不在redis中加字段，need clear逻辑限制在trigger内部，使用300s的时间间隔
  * 细则：
    * 10:50 进度&邮件
    * 插件
      * 11:40 看看是否能不在redis中加参数
      * trigger 负载比线上高——while true导致的，加了个redis无数据时sleep 10
      * wxopenids和step81（getResult）log统计似乎对应补上，待查

* 10/22 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
  * 总结：

    * logreplay
    * 插件
      * Fix polaris_to_ids一直不为空：因为mock数据导致有重复的ids放到其中，而openids_map重复的pop元素会导致异常，导致后续逻辑不走
      * 目前看上去，分流比例、上报atta数符合预期。后续主要关注：放量、机器负载、代码整理
  * 细则：
    * 10:50 进度&邮件
    * 插件
      * 11:34 
        * wxopen和step81对应不上、step5没有？
          * 另外，失败重试，会导致wxopen因为last_q_info而比包里的多
          * 在polaris 503上加个log，这个会影响实验分流
        * 昨晚实验
          * cur polaris in dict有一直为1的
          * 昨晚的没有设置tab实验，导致全走的基线
      * 14:09 getResult返回值和上游接口未对其，导致无结果下发，已fix
      * 15:29 似乎有大list
      * 周六：
        * polaris 有一直pop不出来的
          * 似乎是openids的key和polaris的不一致，导致exception
          * 有重复的redis：mock数据。openids_map是是dict，没有重复的key；但是polaris_to_ids的ids是list，允许重复值。导致后面更新两个dict时，openids_map的key少，导致exception，进而后续的polaris_to_ids不更新，一直卡死

  ## week 46

* 上周工作：

  * 核心进展：
    1、已用100w+1000w的包起实验。日志上分析：分流比例、上报atta数符合预期
    2、本周逐渐放量，观察负载

* 10/25 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
  * 总结：

    * logreplay
    * 插件
      * fix 去重导致的丢id
      * 压测7kw，发现进度慢：节点上限10个，扩容没效果，改为20个节点100上限；trigger cpu不高，getResult 40s耗时，因此调大并发25->100。之后速度从150w/10min上升至300w/10min。
      * 不过原链路说进度似乎偏慢，加上fix bug改了代码，因此00批次将为3kw，保守一点
    * 预计算：写了python，但是似乎请求的时候程序退出了，也每个堆栈什么的
  * 细则：
    * 10:50 进度&邮件
    * logreplay
      * 整理下代码，看看这两天能不能把MR过了
    * 插件
      * 12:01 更新rs的代码，和线上对齐
      * 17:49 同步代码到trpc rs
      * 19:29 改redis为trpc.sz.wx_plugin_trigger_mq.redis.com
      * 吞吐打不上去：
        * 一方面，节点上限是10个，超了会自动缩容，没有注意到
        * 另一方面，getResult耗时太长，40s。trigger大部分时间在等待；另外，cpu也不高。因此加大了一下并发，
      * 22:44 发现由于trigger service的openids去重，会导致有些id被丢掉，需要fix

* 10/25 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr

  * 总结：

    * logreplay
    * 插件
      * 更新代码到trpc rs
      * 晚上压测，原链路吞吐上不去，另外我们的计算的确偏快。因此先停掉7kw的包，明早压测。布好run_trpc.sh，trigger，polaris(brpc rs)，hongfen_rs，hongfen_base.rs，涛涛的基线trpc rs
      * 打算用标签实验来看效果
    * 预计算：
      * 脚本能写出去了，明天联调下内容

  * 细则：

    * 10:50 进度&邮件

    * 插件

      * 14:35 合rs代码到trpc版本。下午压测下

      * 站会：trigger调高并发数要注意：总并发数不要比旧的多，可能打挂rs或者无量

      * 17:24 trpc rs调通：之前是服务名和uri搞混了，新服务的名字可以是hongfendongrecommend_server_trp，但是uri里面是根据pb package来的，所以为trpc.news_rs.recommend_server_trpc.HttpRecommendService

      * 好像trpc框架的服务，不需要再去polaris上建别名了，zkname可以搜到

      * 压测

        * | 时间      | 进度   | 备注                                                         |
          | --------- | ------ | ------------------------------------------------------------ |
          | 20.20开始 |        |                                                              |
          | 20.30     | 2.85   |                                                              |
          | 20.40     | 29.121 | 发现下午测试时，只留了一台trigger，其他都暂停了。33分左右重启 |
          | 20.50     | 79.89  | 差值50.769，总体43.51/h。2.3小时算完。比原链路快。加上thinkxia说旧链路有点慢。因此先暂停。时间20:56分 |
          | 21.00     | 112    | 差值32.11，总体32/6*10=53/h。暂停中                          |

          明早压测，记得起来

        * 实验打算通过标签实验来做。

    * 预计算

      * python运行后悄无声息的退出，待查。
      * traceback堆栈打印出来了，有个assert，调用str.encode转成bytes就行了

* 10/26快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr

  * 总结：

    * logreplay
    * 插件
      * 早上压测正常，稍快。应该是由于trpc扩量1000->1200台
      * 晚上尝试压测7kw新联路+3.4亿 trpc rs。编译问题导致一直卡死到12点，不断重试成功，kexingshi盯到了两点半，没啥太大问题
    * 预计算：
      * 我这边虫洞已初步联调通。后续我这边需要起一个定时任务，监听下发的信号，写id到虫洞

  * 细则：

    * 10:50 进度&邮件

    * 插件

      * | 时间  | 进度           | 备注                      |
        | ----- | -------------- | ------------------------- |
        | 08:04 | 开始           |                           |
        | 08:25 | 100.66M+9.2M   | 前面低活，算的会快些      |
        | 08:40 | 168.26m+14.85m | 900/(168+14)*36/60=2.96h  |
        | 08:50 | 214m+19m       | 900/(214+19)*46/60=2.96h  |
        | 09:00 | 261m+23m       | 900/(261+23)*56/60=2.95h  |
        | 09:10 | 307m+27m       | 900/(307+27)*66/60=2.96h  |
        | 09:20 | 350m+32m       | 900/(350+32)*76/60=2.98h  |
        | 09:30 | 392m+36m       | 900/(392+36)*86/60=3.01h  |
        | 09:40 | 434m+41m       | 900/(434+41)*96/60=3.03h  |
        | 09.50 | 476m+45m       | 900/(476+45)*106/60=3.05h |
        | 10:00 | 519m+49m       | 900/(519+49)*116/60=3.06h |
        | 10:10 | 558m+54m       | 900/(558+54)*126/60=3.08h |
        | 10:20 | 597m+58m       | 900/(596+58)*136/60=3.11h |
        | 10:30 | 636m+62m       | 900/(636+62)*146/60=3.13h |
        | 10:40 | 674m+66m       | 900/(674+66)*156/60=3.16h |
        | 10:50 | 713m+71m       | 900/(713+71)*166/60=3.17h |
        | 11:00 | 747m+73m       | 900/(747+73)*176/60=3.21h |

        吞吐量基本符合预期：一方面，前面低活计算会快些；另外，昨晚trpc rs扩量从1000->1200；之前经验值是5亿/2h左右

      * | 内容                  | 压测时间       | 上线时间 |
        | --------------------- | -------------- | -------- |
        | **7kw tab+3.4亿trpc** | 周三晚         | 周四00   |
        | 2亿tab + 6.8亿 trpc   | 周四早         | 无       |
        | 5亿tab + 6.8亿trpc    | 周四下午、晚上 | 周五00   |
        |                       |                |          |
        | **7kw tab+3.4亿trpc** | 周四下午       |          |
        | 2亿tab + 6.8亿 trpc   | 周四晚上       | 周五00   |
        | 5亿tab + 6.8亿trpc    | 周五早上       | 周五02   |

      * 需要加个offline/preline/online的判断，保证优先级

    * 15:13 参加完实验培训

* 10/28快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
  * 总结：

    * logreplay
    * 插件
      * trigger更新feature：往redis里写计算成功的用户。但是后来又回滚了
  * 细则：
    * 10:50 进度&邮件
    * 插件
      * 判断offline/preline/online优先级
      * 晚上trigger上线了往redis里写id，但是压测的时候感觉有些id丢了，原链路只算了6亿，新链路倒是没啥问题。虽然trigger是在新链路上上的，但还是先回滚，太晚了，也没精力去查，明天再看
    * KM logreplay
      * 但其实还可以理解为同一份流量，打到两个bin上，做diff。这个流量可以是实时的往两个bin打；也可以是在一个bin先录制下来，之后再往另外一个bin打
      * 
      * 刚好最近在接logreplay，趁着这个帖子也说下自己的体会。感觉录制回能很好的提升devops的能力，是个大杀器，大有可为；另外，除了大家都提到的模块自身迭代外，我司的风气也在偏向大仓+主干开发。各个场景、模块的代码都在一块。这也带来个问题，一个场景下的改动可能影响到其他场景，甚至影响到其他模块。也是非常迫切地需要一个工具来保证场景间、模块间代码的相互影响。
      * 大方面大家都说的很好啦，我主要结合最近的使用体会说说，大家参考参考，如果有建议也欢迎指出~
      * logreplay团队给出了两种方案，一个是基goreplay，一个是基于trpc-filter。
        * goreplay的方案是直接监听tcp层流量，对代码没有侵入性，接入成本小，不过有个缺点是，无法录制下游请求的流量。而有些下游请求是时变的，甚至其本身就具有一些随机性。因此可能需要定义下怎样的diff是符合预期、可接受的，这个判断是否能自动化，是否要人介入。另外还有一些其他的问题，比如权限、写请求等
        * 基于trpc-filter的方案可以录制下游请求，理论上可以做到0 diff，但对代码具有较强的侵入性。
      * 新闻这边选择了录制下游流量，即：采用的是基于trpc-filter的方案。
      * trpc-filter是trpc面向切面编程的体现，简单来说就是框架在整个链路预留了一些埋点（或者叫切面），然后我们可以注册一些行为到这些切面上。这些行为对应到代码里是filter。rpc请求前后是有filter的，通过这对filter，我们可以把resp/req弄成一个kv上报存起来：
        * 录制时，上报一个kv：在CLIENT_PRE_RPC_INVOKE根据请求计算出一个key，在CLIENT_POST_RPC_INVOKE把response为value。
        * 回放时，在CLIENT_POST_RPC_INVOKE中根据key查到对应的mock数据，然后进行替换
      * 流程很简单，但是实际使用时还是有些地方需要留意。主要是三个方面的问题，kv的key如何保证录制/回放时是一致的；对于某个key，其value如何保证唯一性，不会出现多值；最后一个主要是性能上的影响
        * 首先，是key的一致性：目前key的计算主要是对请求内容做一个hash。那么如果请求内容变了，会导key查不到。导致这种情况出现的原因有很多，比如：
          * 使用了时间字段。尤其是单位为天、或者小时的。当时无diff，但是过一段时间之后就会出现问题
          * 次序问题：比如我们可能会按分数对doc排序后，分批地mget地去查信息。如果使用非稳定排序，即，相同分的doc分数是不定的，可能排序结果会不一样。那么分批后，mget请求也就变了。比较典型的场景是，因为某些原因这批doc都是默认分，这等于这批doc是乱序的。
          * cache问题：如果开启了cache，则录制时第二次请求实际没有网络调用，即没有录制。回放时，要保证在回放第二个请求前，需先回放了第一个请求，并更新cache。而且考虑到多线程，我们甚至连谁是第一个请求，谁是第二个请求都无法区分。
          * 周期运行的代码：有些代码是间隔一段时间执行的，比如更新一些信息。录制和回放时的间隔会很不一样。另外还要考虑到有时会需要单条回放进行debug的情况。
        * 至于value的多值问题，是如果对于同一个key，存在了多个不同的value，我们无法判断该用哪个value。比较典型的情况是，一个请求成功，而另一个请求失败。这些key对应的调用可能是来自代码的不同地方，用混了会导致后续流程都会受到影响；退一步来说，即便来自相同的地方，比如是一个for循环里的一批并发调用，依然有问题：我们需要在多线程间同步哪些value被用了，哪些value还可选。因此，最好的办法就是不要有重复的调用，想办法差异化这些请求。下面是一些可能出现相同调用的原因：
          * A copy 了B的代码，既然代码都相同，多半请求内容也是相同的
          * 不同的请求在某些条件下退化成相同的：比如我们分别计算出图文、视频的特征，然后去查embedding。但这些特征值可能是一样的（比如某些特征要查redis，但查redis失败了）
          * 本身就存在重复的请求：比如新闻粗排会并行60路召回的doc，并进一步把每一路doc分包去处理。可能有召重复的召回、或者某两路召回存在部分doc相同，在分包后出现重复
        * 性能问题：由于要录制所有下游的请求，录制时要传输的数据可能会相当大。并且我们关掉了cache、把周期运行的代码改成了每次都运行，性能进一步降低。因此不太可能在线上机器做录制。目前是从线上goreplay一份流量到专门的录制环境来进行录制。
      * 可以看到trpc-filter在支持下游录制的同时，也对业务代码产生了一定的侵入性。或许这就是“天下没有免费的午餐吧”。

* 10/29快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
  * 总结：

    * logreplay
    * 插件
      * 周六有个误操作，导致中午02批次未推全；周日00批次推全。今天压测新链路7000w->3亿，无问题放量
      * 加了个回捞机制，消费的id写到redis，并用python脚本回捞
  * 细则：
    * 11:50 进度&邮件
    * 插件
      * 压测
        * 下trigger：往redis里写计算成功的id？
        * 7kw新链路放量至3亿？
      * 周六
        * 操作记录
          * 11:35 run -> bk_dhf, v2->run 
          * 11:40 crontab v1
          * 11:44 电话kexing发现v2未跑
          * 11:53 ps|grep prepare + kill
          * 11:55 清队列
          * 11:57 重跑sh prepare.sh && sh run_trpc_v2.sh
          * 12:15 发现brpc有流量，Husterdang发现11:40分v1没清ps -axu|grep run。代表计算量double
          * 12:23 清队列
          * 12:24 重启v1   sh prepare.sh && sh run_trpc_v1.sh  这样算的快些，避免下午无法按时交付
          * 12:41 断网，脚本运行至sleep15。重新链接后，注释掉之前的包，继续跑run_trpc_v1_dhf.sh
        * consumer redis：4_2021103002_ip
        * 18:45 GetPolaris切到基线，并在trpc上打标签
        * 22:05 开始压测：trigger 回捞redis
          *  hgetall 5_2021103002_ip 
          * lindex pkg_49_dhf_2021103002_3 0













* 插件升级

  * curl -d '{"trace_id":"", "data":[{"wxopenid" :"o04IBACPJkN-cAPMnt8cUQFoqUEQ","conf":"{\"exp\":\"tab\"}"}]}' http://127.0.0.1:10284/RecommendService/GetPolaris

  * 

    ```
    grep wxopen log.log |awk '{a += $NF}END{print a}'
    
    grep "step8 " log.log |awk '{a[$(NF-2)] += $NF}END{for(i in a) {print i, a[i]}}'
    
     grep "trigger com" log.log |awk '{a[$(NF-1)] += $NF}END{for(i in a){print i ,a[i]}}'
    
    ##
    curl -H "Content-Type: application/json" -d '{"trace_id":"77889900", "data":[{"wxopenid":"ojl_Pwr8to28XMiMdcT1eg_YY1FY","conf":"{\"exp\":\"tab\"}"}]}' http://9.24.152.202:11064/trpc.news_rs.recommend_server_trpc.HttpRecommendService/Recommend | python2 -mjson.tool
    
    ##trpc
    curl  -H "Content-Type: application/json"   -d '{"trace_id":"", "data":[{"wxopenid" :"o04IBACPJkN-cAPMnt8cUQFoqUEQ","conf":"{\"exp\":\"tab\"}", "get_bucket_test_response":{"cache_version":"1635237435","version":"TAB_CPP_SDK_1.1.6","depths":{"1":1},"m_bucket_test":{"exp_tfasdf":{"s_bucket_test_id":"100000","params":{},"buckets":[],"i_bucket":0,"group_key_":"exp_tfasdf","strategy_type_":"default","exp_key_":"default","is_allow_list_":0},"wxp_cp_00":{"s_bucket_test_id":"100000","params":{},"buckets":[],"i_bucket":0,"group_key_":"wxp_cp_keep_20210707","strategy_type_":"default","exp_key_":"default","is_allow_list_":0},"content_safe_control_1":{"s_bucket_test_id":"100000","params":{},"buckets":[],"i_bucket":0,"group_key_":"content_safe_exp_first_default","strategy_type_":"default","exp_key_":"default","is_allow_list_":0},"rerank_0":{"s_bucket_test_id":"100000","params":{},"buckets":[],"i_bucket":0,"group_key_":"exp_diaoxing_low_middle_1026","strategy_type_":"default","exp_key_":"default","is_allow_list_":0},"app_new_user":{"s_bucket_test_id":"100000","params":{},"buckets":[],"i_bucket":0,"group_key_":"new_user_Installation_package_copy","strategy_type_":"default","exp_key_":"default","is_allow_list_":0},"numerous_rank_layer":{"s_bucket_test_id":"2721486","params":{},"buckets":[],"i_bucket":3605,"group_key_":"exp_feature_cut_model_0928_copy","strategy_type_":"control","exp_key_":"exp_feature_cut_model_0927_A","is_allow_list_":0},"wxplugin_exp_level1":{"s_bucket_test_id":"100000","params":{},"buckets":[],"i_bucket":0,"group_key_":"exp_wxplugin_ads_test","strategy_type_":"default","exp_key_":"default","is_allow_list_":0},"recall_exps":{"s_bucket_test_id":"100000","params":{},"buckets":[],"i_bucket":0,"group_key_":"exp_news_wxp_dssm_u2i_sample","strategy_type_":"default","exp_key_":"default","is_allow_list_":0},"single_layer":{"s_bucket_test_id":"2805241","params":{"polaris":"trpc.normal.hongfendong_base.wxplugin_rs.main_port"},"buckets":[],"i_bucket":62,"group_key_":"exp_news_wxp_testSplitFlow","strategy_type_":"control","exp_key_":"exp_news_wxp_testSplitFlow_A","is_allow_list_":1}}}}]}' http://9.44.131.241:11045/trpc.news_rs.recommend_server_trpc.HttpRecommendService/Recommend
    
    ## brpc
    curl -d '{"trace_id":"", "data":[{"wxopenid" :"o04IBACPJkN-cAPMnt8cUQFoqUEQ","conf":"{\"exp\":\"tab\"}"}]}' http://9.223.247.246:11833/RecommendService/GetPolaris
    
    curl -d '{"trace_id":"","data":[{"wxopenid":"o04IBACPJkN-cAPMnt8cUQFoqUEQ","conf":"{\"exp\":\"tab\"}","get_bucket_test_response":{"cache_version":"1634562787","version":"TAB_CPP_SDK_1.1.5.2","depths":[{"key":1,"value":1}],"m_bucket_test":{"app_new_user":{"s_bucket_test_id":"100000","i_bucket":0,"group_key_":"new_user_Installation_package_copy","strategy_type_":"default","exp_key_":"default","is_allow_list_":0,"params":{}},"numerous_rank_layer":{"s_bucket_test_id":"2721486","i_bucket":3605,"group_key_":"exp_feature_cut_model_0928_copy","strategy_type_":"control","exp_key_":"exp_feature_cut_model_0927_A","is_allow_list_":0,"params":{}},"wxplugin_exp_level1":{"s_bucket_test_id":"100000","i_bucket":0,"group_key_":"exp_wxplugin_ads_test","strategy_type_":"default","exp_key_":"default","is_allow_list_":0,"params":{}},"sharepage_exp_level1":{"s_bucket_test_id":"100000","i_bucket":0,"group_key_":"sharepage_switch_platform","strategy_type_":"default","exp_key_":"default","is_allow_list_":0,"params":{}},"single_layer":{"s_bucket_test_id":"2805241","i_bucket":0,"group_key_":"exp_news_wxp_testSplitFlow","strategy_type_":"control","exp_key_":"exp_news_wxp_testSplitFlow_A","is_allow_list_":1,"params":{"polaris":"WangWangWang"}},"recall_exps":{"s_bucket_test_id":"100000","i_bucket":0,"group_key_":"exp_news_wxp_dssm_u2i_exp_active_copy","strategy_type_":"default","exp_key_":"default","is_allow_list_":0,"params":{}},"wxp_cp_00":{"s_bucket_test_id":"2367176","i_bucket":69431,"group_key_":"wxp_cp_keep_20210707","strategy_type_":"treatment","exp_key_":"wxp_cp_keep_20210707_C","is_allow_list_":0,"params":{"recall_config":"{\"topCP\":{\"max_num\":50}}","rerank_config":"{\"topI^Cge\":1,\"cpKeepNum\":1,\"cpKeepUpdate\":1,\"itemPool\":{\"thr_ctr_v\":0.1,\"thr_active_d\":15,\"thr_posid\":15}}"}},"exp_tfasdf":{"s_bucket_test_id":"100000","i_bucket":0,"group_key_":"exp_tfasdf","strategy_type_":"default","exp_key_":"default","is_allow_list_":0,"params":{}},"content_safe_control_1":{"s_bucket_test_id":"100000","i_bucket":0,"group_key_":"content_safe_exp_first_default","strategy_type_":"default","exp_key_":"default","is_allow_list_":0,"params":{}},"rerank_0":{"s_bucket_test_id":"100000","i_bucket":0,"group_key_":"exp_diaoxing_middle_high_active_scatter_1015","strategy_type_":"default","exp_key_":"default","is_allow_list_":0,"params":{}}}}}]}' http://127.0.0.1:10284/RecommendService/Recommend | python -mjson.tool
    ```

  * 

  * 16: 00会议

    * 现在的发布流程，开关项如何测的？
    * logreplay
      * 只能测完全相同的请求，新feature要人工diff；
      * 随机性、随机值、cache、set_time；
      * 会有多次、相同的下游请求么？
      * 代码有侵入性（无重复下游、透传server context、多环境路：测试、小流量环境）
    * 如何搭个测试环境，有没有什么坑，trpc配置用线上的？从哪copy流量
    * 痛点——节后给方案
      * 第一步，接入logreplay
      * 整个发布流程的规范——flags的组合？
      * 召回 detools脚本：开发机bin传到测试环境
      * 预发布环境、高中低用户按比例，抽10%。计算资源也按比例设计

* 切换模型：
  * user服务: trpc.Serving.RoughRankingUserFServerTF.PredictInterfaceObj
  * User model key: modelrecallgrp_new_fea_v2_senet.default
  * item服务仍使用线上服务
  * item前缀: pre_rank_902v3
* GetVideoProfileIndex函数删除：因为其行为和ranking不一致。已按照ranking的修改代码
* 写死了模型的一些参数参数：目前模型的target、password不是走实验配置，是写死在代码里的，但模型的前缀、model name是读实验配置。导致需要bin和配置强绑定。本次切换模型先写死，后续再调整、解绑。见 `astra/coarse_ranking/interface/coarse_ranking_context.h`中对`user_model_info`的改动
* 一些format改动
* 更新单测



* 机器使用

* * 3422f793.qqnews.coarse_ranking.tj100041  shuoyang

* 准备起实验
  * experiment_base2.coarse_ranking
  * experiment_test5.coarse_ranking
  * experiment_test4.coarse_ranking

* bazel build :coarse_ranking --define include_replay_logreplay=true --copt="-D LOGREPLAY_DEBUG_STDOUT"







* log replay：
  * 需要手动改配置文件：tracing -> replay
  * 需要用MakeClientContxt
  * diff   https://iwiki.woa.com/pages/viewpage.action?pageId=543187958
    * 可以添加白名单、黑名单
    * 数组：^to_rank_docinfo\[.*].coarse_ranking_score
    * 不要把logreplay的发布到线上，目前放弃了性能，以便更好的处理代码（copy临时对象）
    * 可能的坑
      * 排除随机性：cache、随机值
      * key需要有唯一性：对下游同一个服务的多次调用是否会是同一个key，这回导致回放时乱掉
        * 非模型召回 vs 模型召回的特征处理
        * predict_req.non_video 有可能 == predict_req.video
        * item redis可能是50个相同doc，分包后相同
  * 二期
    * 流量编辑
    * 请求级覆盖RBC
  * 平台机器
    * 11.181.81.0 深圳腾讯深宇DC3号楼0401
    * 9.146.142.2 深圳移动光明DC3号楼1103
    * 9.146.146.139 深圳移动光明DC3号楼1003
    * 9.223.245.252 深圳电信蛇口高科DC0403
    * 9.218.41.78 广州电信永顺DC2号楼2楼3202
    * 11.187.134.102 广州移动华新园ACG16栋6楼0602
    * 11.185.94.199 上海电信奉贤DC2号楼403
    * 11.185.81.95 上海电信奉贤DC2号楼402
  
  
  
* 多环境路由
  * 被调入流量规则 > 主调出流量规则



* 