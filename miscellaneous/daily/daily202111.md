

[toc]

# OKR

## week 46 —— preweek

* 上周工作：

  * 核心进展：
    1、已用100w+1000w的包起实验。日志上分析：分流比例、上报atta数符合预期
    2、本周逐渐放量，观察负载

* 10/25 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
  * 总结：

    * logreplay
    * 插件
      * fix 去重导致的丢id
      * 压测7kw，发现进度慢：节点上限10个，扩容没效果，改为20个节点100上限；trigger cpu不高，getResult 40s耗时，因此调大并发25->100。之后速度从150w/10min上升至300w/10min。
      * 不过原链路说进度似乎偏慢，加上fix bug改了代码，因此00批次将为3kw，保守一点
    * 预计算：写了python，但是似乎请求的时候程序退出了，也每个堆栈什么的
  * 细则：
    * 10:50 进度&邮件
    * logreplay
      * 整理下代码，看看这两天能不能把MR过了
    * 插件
      * 12:01 更新rs的代码，和线上对齐
      * 17:49 同步代码到trpc rs
      * 19:29 改redis为trpc.sz.wx_plugin_trigger_mq.redis.com
      * 吞吐打不上去：
        * 一方面，节点上限是10个，超了会自动缩容，没有注意到
        * 另一方面，getResult耗时太长，40s。trigger大部分时间在等待；另外，cpu也不高。因此加大了一下并发，
      * 22:44 发现由于trigger service的openids去重，会导致有些id被丢掉，需要fix

* 10/25 快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr

  * 总结：

    * logreplay
    * 插件
      * 更新代码到trpc rs
      * 晚上压测，原链路吞吐上不去，另外我们的计算的确偏快。因此先停掉7kw的包，明早压测。布好run_trpc.sh，trigger，polaris(brpc rs)，hongfen_rs，hongfen_base.rs，涛涛的基线trpc rs
      * 打算用标签实验来看效果
    * 预计算：
      * 脚本能写出去了，明天联调下内容

  * 细则：

    * 10:50 进度&邮件

    * 插件

      * 14:35 合rs代码到trpc版本。下午压测下

      * 站会：trigger调高并发数要注意：总并发数不要比旧的多，可能打挂rs或者无量

      * 17:24 trpc rs调通：之前是服务名和uri搞混了，新服务的名字可以是hongfendongrecommend_server_trp，但是uri里面是根据pb package来的，所以为trpc.news_rs.recommend_server_trpc.HttpRecommendService

      * 好像trpc框架的服务，不需要再去polaris上建别名了，zkname可以搜到

      * 压测

        * | 时间      | 进度   | 备注                                                         |
          | --------- | ------ | ------------------------------------------------------------ |
          | 20.20开始 |        |                                                              |
          | 20.30     | 2.85   |                                                              |
          | 20.40     | 29.121 | 发现下午测试时，只留了一台trigger，其他都暂停了。33分左右重启 |
          | 20.50     | 79.89  | 差值50.769，总体43.51/h。2.3小时算完。比原链路快。加上thinkxia说旧链路有点慢。因此先暂停。时间20:56分 |
          | 21.00     | 112    | 差值32.11，总体32/6*10=53/h。暂停中                          |

          明早压测，记得起来

        * 实验打算通过标签实验来做。

    * 预计算

      * python运行后悄无声息的退出，待查。
      * traceback堆栈打印出来了，有个assert，调用str.encode转成bytes就行了

* 10/26快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr

  * 总结：

    * logreplay
    * 插件
      * 早上压测正常，稍快。应该是由于trpc扩量1000->1200台
      * 晚上尝试压测7kw新联路+3.4亿 trpc rs。编译问题导致一直卡死到12点，不断重试成功，kexingshi盯到了两点半，没啥太大问题
    * 预计算：
      * 我这边虫洞已初步联调通。后续我这边需要起一个定时任务，监听下发的信号，写id到虫洞

  * 细则：

    * 10:50 进度&邮件

    * 插件

      * | 时间  | 进度           | 备注                      |
        | ----- | -------------- | ------------------------- |
        | 08:04 | 开始           |                           |
        | 08:25 | 100.66M+9.2M   | 前面低活，算的会快些      |
        | 08:40 | 168.26m+14.85m | 900/(168+14)*36/60=2.96h  |
        | 08:50 | 214m+19m       | 900/(214+19)*46/60=2.96h  |
        | 09:00 | 261m+23m       | 900/(261+23)*56/60=2.95h  |
        | 09:10 | 307m+27m       | 900/(307+27)*66/60=2.96h  |
        | 09:20 | 350m+32m       | 900/(350+32)*76/60=2.98h  |
        | 09:30 | 392m+36m       | 900/(392+36)*86/60=3.01h  |
        | 09:40 | 434m+41m       | 900/(434+41)*96/60=3.03h  |
        | 09.50 | 476m+45m       | 900/(476+45)*106/60=3.05h |
        | 10:00 | 519m+49m       | 900/(519+49)*116/60=3.06h |
        | 10:10 | 558m+54m       | 900/(558+54)*126/60=3.08h |
        | 10:20 | 597m+58m       | 900/(596+58)*136/60=3.11h |
        | 10:30 | 636m+62m       | 900/(636+62)*146/60=3.13h |
        | 10:40 | 674m+66m       | 900/(674+66)*156/60=3.16h |
        | 10:50 | 713m+71m       | 900/(713+71)*166/60=3.17h |
        | 11:00 | 747m+73m       | 900/(747+73)*176/60=3.21h |

        吞吐量基本符合预期：一方面，前面低活计算会快些；另外，昨晚trpc rs扩量从1000->1200；之前经验值是5亿/2h左右

      * | 内容                  | 压测时间       | 上线时间 |
        | --------------------- | -------------- | -------- |
        | **7kw tab+3.4亿trpc** | 周三晚         | 周四00   |
        | 2亿tab + 6.8亿 trpc   | 周四早         | 无       |
        | 5亿tab + 6.8亿trpc    | 周四下午、晚上 | 周五00   |
        |                       |                |          |
        | **7kw tab+3.4亿trpc** | 周四下午       |          |
        | 2亿tab + 6.8亿 trpc   | 周四晚上       | 周五00   |
        | 5亿tab + 6.8亿trpc    | 周五早上       | 周五02   |

      * 需要加个offline/preline/online的判断，保证优先级

    * 15:13 参加完实验培训

* 10/28快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
  * 总结：

    * logreplay
    * 插件
      * trigger更新feature：往redis里写计算成功的用户。但是后来又回滚了
  * 细则：
    * 10:50 进度&邮件
    * 插件
      * 判断offline/preline/online优先级
      * 晚上trigger上线了往redis里写id，但是压测的时候感觉有些id丢了，原链路只算了6亿，新链路倒是没啥问题。虽然trigger是在新链路上上的，但还是先回滚，太晚了，也没精力去查，明天再看
    * KM logreplay
      * 但其实还可以理解为同一份流量，打到两个bin上，做diff。这个流量可以是实时的往两个bin打；也可以是在一个bin先录制下来，之后再往另外一个bin打
      * 
      * 刚好最近在接logreplay，趁着这个帖子也说下自己的体会。感觉录制回能很好的提升devops的能力，是个大杀器，大有可为；另外，除了大家都提到的模块自身迭代外，我司的风气也在偏向大仓+主干开发。各个场景、模块的代码都在一块。这也带来个问题，一个场景下的改动可能影响到其他场景，甚至影响到其他模块。也是非常迫切地需要一个工具来保证场景间、模块间代码的相互影响。
      * 大方面大家都说的很好啦，我主要结合最近的使用体会说说，大家参考参考，如果有建议也欢迎指出~
      * logreplay团队给出了两种方案，一个是基goreplay，一个是基于trpc-filter。
        * goreplay的方案是直接监听tcp层流量，对代码没有侵入性，接入成本小，不过有个缺点是，无法录制下游请求的流量。而有些下游请求是时变的，甚至其本身就具有一些随机性。因此可能需要定义下怎样的diff是符合预期、可接受的，这个判断是否能自动化，是否要人介入。另外还有一些其他的问题，比如权限、写请求等
        * 基于trpc-filter的方案可以录制下游请求，理论上可以做到0 diff，但对代码具有较强的侵入性。
      * 新闻这边选择了录制下游流量，即：采用的是基于trpc-filter的方案。
      * trpc-filter是trpc面向切面编程的体现，简单来说就是框架在整个链路预留了一些埋点（或者叫切面），然后我们可以注册一些行为到这些切面上。这些行为对应到代码里是filter。rpc请求前后是有filter的，通过这对filter，我们可以把resp/req弄成一个kv上报存起来：
        * 录制时，上报一个kv：在CLIENT_PRE_RPC_INVOKE根据请求计算出一个key，在CLIENT_POST_RPC_INVOKE把response为value。
        * 回放时，在CLIENT_POST_RPC_INVOKE中根据key查到对应的mock数据，然后进行替换
      * 流程很简单，但是实际使用时还是有些地方需要留意。主要是三个方面的问题，kv的key如何保证录制/回放时是一致的；对于某个key，其value如何保证唯一性，不会出现多值；最后一个主要是性能上的影响
        * 首先，是key的一致性：目前key的计算主要是对请求内容做一个hash。那么如果请求内容变了，会导key查不到。导致这种情况出现的原因有很多，比如：
          * 使用了时间字段。尤其是单位为天、或者小时的。当时无diff，但是过一段时间之后就会出现问题
          * 次序问题：比如我们可能会按分数对doc排序后，分批地mget地去查信息。如果使用非稳定排序，即，相同分的doc分数是不定的，可能排序结果会不一样。那么分批后，mget请求也就变了。比较典型的场景是，因为某些原因这批doc都是默认分，这等于这批doc是乱序的。
          * cache问题：如果开启了cache，则录制时第二次请求实际没有网络调用，即没有录制。回放时，要保证在回放第二个请求前，需先回放了第一个请求，并更新cache。而且考虑到多线程，我们甚至连谁是第一个请求，谁是第二个请求都无法区分。
          * 周期运行的代码：有些代码是间隔一段时间执行的，比如更新一些信息。录制和回放时的间隔会很不一样。另外还要考虑到有时会需要单条回放进行debug的情况。
        * 至于value的多值问题，是如果对于同一个key，存在了多个不同的value，我们无法判断该用哪个value。比较典型的情况是，一个请求成功，而另一个请求失败。这些key对应的调用可能是来自代码的不同地方，用混了会导致后续流程都会受到影响；退一步来说，即便来自相同的地方，比如是一个for循环里的一批并发调用，依然有问题：我们需要在多线程间同步哪些value被用了，哪些value还可选。因此，最好的办法就是不要有重复的调用，想办法差异化这些请求。下面是一些可能出现相同调用的原因：
          * A copy 了B的代码，既然代码都相同，多半请求内容也是相同的
          * 不同的请求在某些条件下退化成相同的：比如我们分别计算出图文、视频的特征，然后去查embedding。但这些特征值可能是一样的（比如某些特征要查redis，但查redis失败了）
          * 本身就存在重复的请求：比如新闻粗排会并行60路召回的doc，并进一步把每一路doc分包去处理。可能有召重复的召回、或者某两路召回存在部分doc相同，在分包后出现重复
        * 性能问题：由于要录制所有下游的请求，录制时要传输的数据可能会相当大。并且我们关掉了cache、把周期运行的代码改成了每次都运行，性能进一步降低。因此不太可能在线上机器做录制。目前是从线上goreplay一份流量到专门的录制环境来进行录制。
      * 可以看到trpc-filter在支持下游录制的同时，也对业务代码产生了一定的侵入性。或许这就是“天下没有免费的午餐吧”。

* 10/29快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
  * 总结：

    * logreplay
    * 插件
      * 周六有个误操作，导致中午02批次未推全；周日00批次推全。今天压测新链路7000w->3亿，无问题放量
      * 加了个回捞机制，消费的id写到redis，并用python脚本回捞
  * 细则：
    * 11:50 进度&邮件
    * 插件
      * 压测
        * 下trigger：往redis里写计算成功的id？
        * 7kw新链路放量至3亿？
      * 周六
        * 操作记录
          * 11:35 run -> bk_dhf, v2->run 
          * 11:40 crontab v1
          * 11:44 电话kexing发现v2未跑
          * 11:53 ps|grep prepare + kill
          * 11:55 清队列
          * 11:57 重跑sh prepare.sh && sh run_trpc_v2.sh
          * 12:15 发现brpc有流量，Husterdang发现11:40分v1没清ps -axu|grep run。代表计算量double
          * 12:23 清队列
          * 12:24 重启v1   sh prepare.sh && sh run_trpc_v1.sh  这样算的快些，避免下午无法按时交付
          * 12:41 断网，脚本运行至sleep15。重新链接后，注释掉之前的包，继续跑run_trpc_v1_dhf.sh
        * consumer redis：4_2021103002_ip
        * 18:45 GetPolaris切到基线，并在trpc上打标签
        * 22:05 开始压测：trigger 回捞redis
          *  hgetall 5_2021103002_ip 
          * lindex pkg_49_dhf_2021103002_3 0

## week 47

* 11/01快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr
  * 总结：

    * logreplay
    * 插件
      * 7000w->3亿：压测不稳定，明天02批次再上
  * 细则：
    * 11:10 进度&邮件
    * 插件
      * 回捞
        * 改成按下标取？不要rpop
        * 后续的脚本完善下：run.sh怎么改
      * 新链路放量7000w->3亿?
        * Run v1 v2中，tab且未设置ons的都全切
        * 压测发现：要么trpc在前半截导致无量负载太高，要么后半截负载上不去，因此挪到明天02批次再上

* 11/02快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr

  * 总结：

    * logreplay
    * 插件
      * boost卡主，尝试解决中

  * 细则：

    * 11:10 进度&邮件

    * 插件：

      * 压测

      * | 时间  | 进度                                           | 备注 |
        | ----- | ---------------------------------------------- | ---- |
        | 11:40 |                                                | 开始 |
        | 11:50 | can(17,15,10, 200) <br/> False 32 32.0 640     |      |
        | 12:00 | can(38,49,20, 200)<br/>True 87 43.5 869        |      |
        | 12:20 | can(84,104,40, 200)<br/>True 188 47.0 940.0    |      |
        | 13:00 | can(185,221,80, 200)<br/>True 406 50.75 1015.0 |      |
        | 14:00 | can(272,411,140, 200)<br/>True 683 48.78 975   |      |
        | 14:10 | can(272,446,150, 200)<br/>True 718 47.86 957   |      |
        | 14:20 | can(272,482,160, 200)<br/>True 754 47.125 942  |      |

        | 时间  | 进度                                    | 备注 |
        | ----- | --------------------------------------- | ---- |
        | 21:11 |                                         |      |
        | 21:30 | can(36,46,20, 200)<br/>True 82 41.0 819 |      |
        |       |                                         |      |

        测试环境zkname访问不到，可能需要看看怎么改成polaris sdk——已经解决，但kexing建议先不弄，先搞到正式环境

* 11/03快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr

  * 总结：

    * logreplay
    * 插件
      * boost卡主，尝试解决中

  * 细则：

    * 11:10 进度&邮件

    * 插件

      * 08:00 查core，给出原因。浩东fix

      * boost编译：

      * 计算进度

      * | 时间  | 进度                                          | 备注 |
        | ----- | --------------------------------------------- | ---- |
        | 12:11 |                                               |      |
        | 12:20 | can(27,13,10, 200)<br/>False 40 40.0 800.0    |      |
        | 13:00 | can(138,133,50, 200)<br/>True 271 54.2 1084.0 |      |
        | 14:10 | can(306,262,120 ,200)<br/>True 568 47.3 946   |      |

* 11/04快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr

  * 总结：

    * logreplay
    * 插件
      * nameapi -> 北极星sdk

  * 细则：

    * 11:10 进度&邮件
    * 插件
      * 北极星sdk会导致业务log不输出，应该是import次序问题
      * 23:16 开始压测

* 11/05快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr

  * 总结：

    * logreplay
    * 插件
      * 尾部数据处理进度慢。和batch积累的时间关系不大。似乎是process_num导致的等待

  * 细则：

    * 11:10 进度&邮件

    * 插件

      * 找时间过一遍回捞流程

      * 压测看看为啥虫洞量会偏低

      * | 时间  | 进度                                                        | 备注             |
        | ----- | ----------------------------------------------------------- | ---------------- |
        | 16:37 |                                                             |                  |
        | 16:50 |                                                             |                  |
        | 17:00 | 13+28                                                       |                  |
        | 17:10 | 15+57                                                       | 清队列，准备重压 |
        | 17:34 |                                                             | 重压             |
        | 18:01 | can(69,82,30,200)<br/>True 151 50.33 1006                   |                  |
        | 18:30 | can(175,118,60,200)<br/>True 293 48.833333333333336 976.666 |                  |
        | 19:15 | can(259,205,100,200)<br/>True 464 46.4 927                  |                  |
        | 20:20 | can(261,420,170,200)<br/>False 681 40.05882352941177 80     |                  |

    * 周六

      * | 时间  | 进度                                            |      |
        | ----- | ----------------------------------------------- | ---- |
        | 12:00 |                                                 |      |
        | 12:40 | can(104,126,40,200)<br/>True 230 57.5 1150      |      |
        | 13:10 | can(235,189 ,70,200)<br/>True 424 60.5 1211     |      |
        | 17:56 | 开始压测                                        |      |
        | 18:50 | can(98,136,50,200)<br/>True 234 46.8 936.0      |      |
        | 19:00 | can(114,163,60,200)<br/>True 277 46.16 923      |      |
        | 19:20 | can(142,206,80,200)<br/>True 348 43.5 869       |      |
        | 19:30 | can(154,227,90,200)<br/>True 381 42.36 846      |      |
        | 19:40 | can(166,246,100,200)<br/>True 412 41.2 824.0    |      |
        | 19:50 | can(178,264,110,200)<br/>False 442 40.18 803.6  |      |
        | 20:00 | can(189,283,120,200)<br/>False 472 39.33 786.67 |      |
        | 20:10 | can(200,302,130,200)<br/>False 502 38.62 772.31 |      |
        | 20:20 | can(210,320,140,200)<br/>False 530 37.86 757.14 |      |
        | 20:30 | can(221,338,150,200)<br/>False 559 37.27 745.33 |      |
        | 20:40 | can(232,357,160,200)<br/>False 589 36.81 736.25 |      |

        [mqq@11-186-251-82 ~/code/log]$ grep wxopen log.log |awk '{a[$(NF-1)] += $NF; b[$(NF-1)] += 1}END{for(i in a){print i ,a[i],b[i], a[i]/b[i]}}'trpc.news_rs_exp11.recommend_server_trpc.HttpRecommendService 726 375 1.936
        trpc.news_rs_exp2.recommend_server_trpc.HttpRecommendService 1730 524 3.30153
        trpc.news_rs_experiment5.HttpRecommendService 3704 572 6.47552
        trpc.news_rs_exp6.recommend_server_trpc.HttpRecommendService 3456 569 6.07381
        trpc.news_rs_exp10.recommend_server_trpc.HttpRecommendService 3591 573 6.26702
        trpc.news.rs.experiment1_xf 21673 593 36.5481
        trpc.news_rs_exp8.recommend_server_trpc.HttpRecommendService 1025 432 2.37269
        trpc.news_rs.recommend_server_exp20.HttpRecommendService 3605 568 6.34683
        wxplugin_exp20_123 17754 584 30.4007
        trpc.news_rs.recommend_server_trpc_lucky.HttpRecommendService 6057 576 10.5156
        trpc.news_rs_exp14.recommend_server_trpc.HttpRecommendService 1866 521 3.58157
        trpc.news_rs.recommend_server_trpc.HttpRecommendService 827818 4518 183.227
        trpc.news_rs_exp9.recommend_server_trpc.HttpRecommendService 3543 568 6.23768
        trpc.news_rs.recommend_server_trpc_sonwnli.HttpRecommendService 37007 597 61.9883

      * 小流量的batch非常低。算上基线，均值才80

      * | 时间  | 进度                                            | 备注                                                         |
        | ----- | ----------------------------------------------- | ------------------------------------------------------------ |
        | 21:37 |                                                 |                                                              |
        | 22:10 | can(64,83,30,200)<br/>True 147 49.0 980.0       | 回滚rs镜像                                                   |
        | 22:20 | can(78,108,40,200)<br/>True 186 46.5 930.0      |                                                              |
        | 20:30 | can(96,138,50,200)<br/>True 234 46.8 936.0      |                                                              |
        | 20:40 | can(111,164,60,200)<br/>True 275 45.83 916.67   |                                                              |
        | 22:50 | can(126,189,70,200)<br/>True 315 45.0 900.0     |                                                              |
        | 23:00 | can(143,216,80,200)<br/>True 359 44.88 897.5    |                                                              |
        | 23:10 | can(158,242,90,200)<br/>True 400 44.44 888.89   |                                                              |
        | 23:20 | can(176,269,100,200)<br/>True 445 44.5 890.0    |                                                              |
        | 23:30 | can(192,296,110,200)<br/>True 488 44.36 887.27  |                                                              |
        | 23:40 | can(205,321,120,200)<br/>True 526 43.83 876.67  | neillguo告知我只回滚了200台，其他机器他在回滚                |
        | 23:50 | can(217,334,130,200)<br/>True 551 42.38 847.69  |                                                              |
        | 24:00 | can(223,338,140,200)<br/>False 561 40.07 801.43 | 这里进度基本未增加，似乎是因为neillguo，目前538台机器healthy |
        | 24:10 | can(234,341,140,200)<br/>True 575 41.07 821.43  | 修正10min                                                    |
        | 24:20 | can(253,349,150,200)<br/>False 602 40.13 802.67 |                                                              |
        | 24:30 | can(260,365,160,200)<br/>False 625 39.06 781.25 |                                                              |
        | 24:40 | can(262,381,170,200)<br/>False 643 37.82 756.47 |                                                              |
        | 24:50 | can(263,395,180,200)<br/>False 658 36.56 731.11 |                                                              |
        | 1:00  | can(264,407,190,200)<br/>False 671 35.32 706.32 |                                                              |

        

## week 48

* 11/08快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr

  * 总结：

    * logreplay
    * 插件
      * 拖尾问题已解，process num可去掉

  * 细则：

    * 11:10 进度&邮件

    * 插件

      * trpc推全，关注进度

        * | 时间  | 进度                                             | 备注                                                        |
          | ----- | ------------------------------------------------ | ----------------------------------------------------------- |
          | 11:40 | 开始计算                                         |                                                             |
          | 12:00 | can(38,34,20,200)<br/>False 72 36.0 720.0        |                                                             |
          | 12:10 | can(59,74,30,200)<br/>True 133 44.33 886.67      |                                                             |
          | 12:20 | can(88,109,40,200)<br/>True 197 49.25 985.0      |                                                             |
          | 12:30 | can(114, 142,50,200)<br/>True 256 51.2 1024.0    |                                                             |
          | 12:40 | can(140, 175,60,200)<br/>True 315 52.5 1050.0    |                                                             |
          | 12:50 | can(166, 209,70,200)<br/>True 375 53.57 1071.43  |                                                             |
          | 13:00 | can(193, 240,80,200)<br/>True 433 54.12 1082.5   |                                                             |
          | 14:00 | can(285, 449,140,200)<br/>True 734 52.43 1048.57 |                                                             |
          | 14:20 | can(287,518,160,200)<br/>True 805 50.31 1006.25  |                                                             |
          | 14:30 | can(287,524,170,200)<br/>True 811 47.71 954.12   | 调小Last_mock累计的线程数<br />-100, -200,- 300, -400,-1000 |
          |       |                                                  |                                                             |
          | 17:08 | 开始压测                                         |                                                             |
          | 17:20 | can(20,33,10,200)<br/>True 53 53.0 1060.0        |                                                             |
          | 17:30 | can(39,72,20,200)<br/>True 111 55.5 1110.0       |                                                             |
          | 18:30 | can(188,285, 80,200)<br/>True 473 59.12 1182.5   |                                                             |
          | 19:50 | can(246,526, 160,200)<br/>True 772 48.25 965.0   |                                                             |
          |       |                                                  |                                                             |
          | 21:44 | 开始压测                                         |                                                             |
          | 22:40 | can(149,228, 50,200)<br/>True 377 75.4 1508.0    |                                                             |
          | 23:20 | can(247,351, 90,200)<br/>True 598 66.44 1328.89  |                                                             |
          | 23:30 | can(258,388, 100,200)<br/>True 646 64.6 1292.0   |                                                             |
          | 23:40 | can(265,426, 110,200)<br/>True 691 62.82 1256.36 |                                                             |
          | 24:00 | can(265,510, 130,200)<br/>True 775 59.62 1192.31 |                                                             |
          | 24:10 | can(265,555, 140,200)<br/>True 820 58.57 1171.43 |                                                             |

* 11/09快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr

  * 总结：

    * logreplay
    * 插件
      * 拖尾问题已解，process num可去掉

  * 细则：

    * 11:10 进度&邮件
    * 插件
      * 线上计算进度有问题，目前怀疑是回捞redis写满，导致后续的进度redis信息没写

* 11/10快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr

  * 总结：

    * logreplay
    * 插件
      * 存在返回码200但item < 4的情况，这些id会被丢弃。并且这种情况是整个请求全部id都item < 4；因此对这种情况直接判为失败，不从队列中pop，以便后续重试

  * 细则：

    * 11:10 进度&邮件

    * 插件

      * 似乎又有回捞redis写满的问题

      * 早上有些没算完的，因此先把process num加回来，另外改大LastMock的process num为20w

      * 线上返回了大量的item<4的，目测是召回redis有问题。但没有确切证据。加监控再后续观察

        * | 时间  | 进度                                             | 备注 |
          | ----- | ------------------------------------------------ | ---- |
          | 21:20 |                                                  |      |
          | 21:30 | can(29, 28, 10,200)<br/>True 57 57.0 1140.0      |      |
          | 22:10 | can(193, 272, 110,200)<br/>True 465 42.27 845.45 |      |
          |       |                                                  |      |
          | 23:50 | 开始压测——有返回码为200，但是item < 4的，大概2%  |      |
          | 24:21 | 重新压测——多删了行代码                           |      |
          | 24:40 | can(56,62, 20,200)<br/>True 118 59.0 1180.0      |      |

* 11/11快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr

  * 总结：

    * logreplay
    * 插件
      * 除了2个包外，其他旧链路已迁到新链路

  * 细则：

    * 11:10 进度&邮件

    * 插件

      * | 时间  | 进度                                          | 备注                                      |
        | ----- | --------------------------------------------- | ----------------------------------------- |
        | 16:45 | 开始压测                                      |                                           |
        | 18:00 | can(2,363, 75,200)<br/>True 365 48.67 973.33  |                                           |
        | 18:10 | can(2,398, 85,200)<br/>True 400 47.06 941.18  | 无量似乎负载没上去，扩点trigger节点：50台 |
        | 19:50 | can(2,804, 185,190)<br/>True 806 43.57 827.78 |                                           |

        曝光redis上云

      * 曝光代码

      * trigger监控

* 11/12快速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr

  * 总结：

    * logreplay
    * 插件
      * 优化回塞

  * 细则：

    * 11:10 进度&邮件

    * 插件

      * 虫洞、预计算压测

      * redis

      * polaris层？

        * | 时间  | 进度                                          | 备注              |
          | ----- | --------------------------------------------- | ----------------- |
          | 16:45 | 压测开始                                      |                   |
          | 17:10 | can(0,161, 25,180)<br/>True 161 64.4 1159.2   | 注释了process num |
          | 17:50 | can(0,387, 65,180)<br/>True 387 59.54 1071.69 |                   |
          | 19:30 | can(2,805, 165,180)<br/>True 807 48.91 880.36 |                   |

        

## week 49

* 上周工作
* 11/15快速的提升工程素养，和团队一起将粗排建设成一流水平
  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
    * okr

  * 总结：

    * logreplay
    * 插件
      * 回塞优化：单个改为批次
      * 压测曝光redis迁移腾讯云

  * 细则：

    * ~~11:10 进度&邮件~~
    * 插件
      * 线上gap偏大，回塞消费过慢
      * 优化回塞，从单个改为批量写入redis
      * 压测曝光迁移腾讯云，无明显异常
* 11/16速的提升工程素养，和团队一起将粗排建设成一流水平
  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783

  * 总结：

    * logreplay
    * 插件
      * 继续压测redis、压测回塞

  * 细则：

    * 11:00 进度&邮件
    * 插件
      * 曝光redis上云：压测redis
      * 优化回塞
* 11/17 速的提升工程素养，和团队一起将粗排建设成一流水平
  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783

  * 总结：

    * logreplay
      * 解决conflict，目前似乎跑不起来
    * 插件
      * 调试虫洞参数

  * 细则：

    * 11:00 进度&邮件
    * logreplay
      * 解决conflict
    * 插件
      * todo: go 重构
      * 调试虫洞
        * linger_time = 1000+异步，qps下午过高200%->1200%（一般200-400%）
        * linger_time=32k，晚上压了2亿数据。qps使用率约涨100%，连接数涨至100%（平均包大小从1.8 -> 3左右？）
        * 明天对一下，找个时间全量压测
      * 压测回捞
* 11/18 速的提升工程素养，和团队一起将粗排建设成一流水平
  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783

  * 总结：

    * logreplay
    * 插件
      * 

  * 细则：

    * 11:00 进度&邮件
    * 插件
      * 压测回塞：08：10开始压测
        * 压测结果ok，回塞未导致耗时明显拖尾
      * 虫洞，联调中
    * logreplay 疑似diff点
      * DoFaissSearch
      * ReadFromRedis
* 11/19 速的提升工程素养，和团队一起将粗排建设成一流水平
  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783

  * 总结：

    * logreplay
    * 插件
      * 联调虫洞：trigger中的已经ok了；监听的似乎吞吐量比较低

  * 细则：

    * 11:00 进度&邮件
    * 插件
      * redis 取消计费
      * 虫洞
    * logreplay 疑似diff点
      * DoFaissSearch
      * ReadFromRedis
      * float：似乎超过有效位数的值也会影响hash——ps，截图左边错位了，是上一行
        * ![image-20211119202103170](/Users/jeashtower/Desktop/work_tips/daily/2021/image-20211119202103170.png)

## week 50

* 11/22 速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783

  * 总结：

    * logreplay
      * 目前有很低的diff，1/500
    * 插件
      * 虫洞：压测后留在线上
      * 曝光redis上云：读/写代码已注释

  * 细则：

    * 11:00 进度&邮件
    * 插件
      * 调虫洞参数，想办法把流量打起来
    * logrepaly
      * external/trpc_cpp/trpc/filter/logreplay/logreplay_client_filter.cc:146
      * astra/coarse_ranking/components/searchrch_index_clinet.cpp:90
      * external/search_client_lib/search_client/helper/custom_helper.cc:191

* 11/23 速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783

  * 总结：

    * logreplay
      * data_fetcher_.ConvertToRawSample 相同的输入有diff
    * 插件
      * 似乎北极sdk不会更新数据

  * 细则：

    * 11:10 进度&邮件

    * logreplay

      *  data_fetcher_.ConvertToRawSample 相同的输入有diff

      * ```
        grep '=== 190 184467440734037810' ../../log/trpc.log |awk '{print substr($0, index($0, $6))}' |awk '{l = split($0, a, "doc_id"); for (i =0;i<l;++i) {print a[i]}}' | sort |uniq -c > tmp1
        ```

      * 

    * 插件

      * 似乎北极星sdk不会更新？
        * 20:07 增加 11.160.138.230:11467
        * 20:26 删除 11.154.145.164:11396
        * 21:19 增加 exp18  11.160.139.127:11428
        * 21:55 删除 exp18 11.186.252.33:11442

* 11/24 速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783

  * 总结：

    * logreplay
      * logreplay-redis代码没编进去，logreplay-sdk没对重复请求报错
    * 插件
      * 北极星回滚回ons

  * 细则：

    * 11:10 进度&邮件
    * logreplay
      * SetupClickSequence有diff
      * 艹
        * logreplay未正确处理重复值的问题——break了
        * trpc-redis少了个define，导致部分代码没开启，差异化请求的字段没设置上
    * 插件 
      * todo  \# data = "|11/24/2021 21:07:20|" + '|'.join(attastr)

* 11/25速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783

  * 总结：

    * logreplay
      * 基本稳定，整理MR，另外反馈下trpc最新版本的CallerName问题
    * 插件
      * 北极星回滚回ons

  * 细则：

    * 11:10 进度&邮件
    * logreplay:
      * 模型召回的dnn/dnnhot/dnncold的trigger name都是dnn。需要区分
      * Debug 导致RIF全请求的id列表为空
      * trpc新版把server context的caller name搞没了
    * 插件
      * formal.hongfendong.wxplugin_trigger.sz100570 回滚回北极星版本，以便排查问题
      * 不查了：trigger重构+北极星开发装死

* 11/26速的提升工程素养，和团队一起将粗排建设成一流水平

  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783

  * 总结：

    * logreplay

  * 细则：

    * 11:00 进度&邮件

## week 51

* 11/29 速的提升工程素养，和团队一起将粗排建设成一流水平
  * 长期：core guide、gmock，bazel、hana

  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检

  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783

  * 总结：

    * logreplay
      * astra-MR
    * 插件
      * 验收预计算N调
      * 值周

  * 细则：

    * 11:00 进度&邮件
    * logreplay
      * MR rebase 
        * 晚上合进去了
      * logreplay-MR
      * 开关
    * 插件
      * 验收预计算N条
      * 值周，压测
        * 20:15 压测
        * 21:30 不明原因翻车，吞吐率低。重压
* 11/30 速的提升工程素养，和团队一起将粗排建设成一流水平
  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
  * 总结：
    * logreplay
      * 多环境路由：trpc框架配置有问题，改了之后可以一键关闭多环境路由。但是leaf的索引还是报错，待查
    * 插件
      * 值日：combo、提前批复用redis
  * 细则
    * 12:00 进度&邮件
    * logreplay
    * 值日
      * 预计算批次的隔离：复用旧链路的redis
    * 其他
      * 手Q
        * 4亿 用户，红点1700w, 个性化？
        * 2开算，8点推
      * push
        * 地域2kw，？1kw，兴趣几十万
        * 1.5亿，每日7、8轮
        * 曝光历史不准确的问题：trigger透传2天未用（有编选）；自己存了5天（无编选，无下发避让策略）
* 12/01 速的提升工程素养，和团队一起将粗排建设成一流水平
  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
  * 总结：
    * logreplay
      * leaf报错待查、trpc新版本待适配
    * 插件
      * 值日：combo1130需再观察一天
  * 细则
    * 12:00 进度&邮件
    * logreplay
      * leaf的报错待查
      * core & trpc版本
    * 插件
      * combo1130效果——继续观察
      * 提前批用新的redis，调整配套的一些列代码、脚本
      * 明日00批次后，早上00批次时间需要回滚
    * 其他：tapd、自评
* 12/02 速的提升工程素养，和团队一起将粗排建设成一流水平
  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳、体检
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
  * 总结：
    * logreplay
      * 尝试关闭多环境路由，删除了出路由规则，但是目前发现有很多超时，主要是trigger，导致后面的流程都不走。另外，监控上看不到下游ip
    * 插件
      * Combo1130 合入，combo1202上实验环境
  * 细则
    * 11:20 进度&邮件&tapd
    * logreplay
      * external/trpc_cpp/trpc/naming/polaris/polaris_selector.cc:443
      * 尝试修改网页上的路由规则——新版保存逻辑太坑爹了，一下午白调，根本没起效果
    * 插件
      * 值周 
        * 15:20 combo1130合入，并开始压测
    * 其他：自评、报销
      * 剖析&反馈
      * 反思工作
      * 方法论
* 12/03 速的提升工程素养，和团队一起将粗排建设成一流水平
  * 长期：core guide、gmock，bazel、hana
  * 低优先级

    * 香港保险、作业
    * 股票、安居、居住证
    * should report的实现？
    * 周末：攀岩、消防绳
  * 任务队列：深度召回

    * deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
  * 总结：
    * logreplay
      * 深圳set写成了tj，导致超时。——测试环境已无多环境路由问题
      * 尝试调了下流水线，但后面samuelcui调通了
    * 插件
      * Combo1130 合入，combo1202上实验环境
  * 细则
    * 11:20 进度&邮件&tapd
    * logreplay
      * 10:30 看看正式环境是否有超时问题——原来是我深圳的set写的tj，所以导致跨机房访问超时
      * 流水线改动
        * 运行时
          * 设置record、replay环境；设置logreplay-id和token
        * 回放验证：
          * 2
            * 取消生成tag名称
          * 3
            * 发布镜像原子:原子运行环境
            * 拉取方式从TAG改为COMMIT_ID
            * code_tag改为master
            * 源码分支改为maste
    * 插件
      * 周六
        * exp8环境没起来——昨天压测后半段发布的镜像，后半段没有留意进度。14:45-16:30  ，镜像发布时间16:00
        * tail -100000 log.log |grep 'item < 4' |awk '{print $9,$10, $11}'|wc -l && tail -100000 log.log |grep 'resp
          onse code' |wc -l
    * 其他：自评、报销
      * 绩效&自评
      * 剖析&反馈
      * 反思工作
      * 方法论

## week 52

* 上周工作：
  * logreplay
    * 关闭多环境路由，查明一个5月至今的北极星配置bug
    * 适配trpc 0.9.3
  * 插件
    * 值周
    * 验收预计算N条
* 本周重点
  * 剖析&反馈
  * 反思工作
  * 方法论
  * 工作居住证
* 长期
  * 长期：core guide、gmock，bazel、hana
  * 中期：
    * 了解业界技术：COLD等
    * 深度召回deep retrieval https://arxiv.org/abs/2007.07203
      TDM https://zhuanlan.zhihu.com/p/78941783
  * 低优：
    * 香港保险、安居计划
    * 攀岩，消防绳？高楼火灾逃生
* 12/06
  * 总结：
    * logreplay
      * 深圳set写成了tj，导致超时。——测试环境已无多环境路由问题
      * 尝试调了下流水线，但后面samuelcui调通了
    * 插件
      * Combo1130 合入，combo1202上实验环境
  * 细则
    * 11:20 进度&邮件&tapd
    * logreplay
      * 调试流水线，明日上线
    * 插件
      * 值周收尾：似乎有些wxplugin_exp20_123一直503。导致1‰一直没算。先重启trigger
    * 其他：
      * 报销
      * 剖析&反馈
      * 反思工作
      * 方法论
* 12/07
  * 总结：
    * logreplay
      * 已发一次上线验证流水线全链路
    * 插件
      * 协助排查trigger吞吐量问题：write_redis卡住、无量部分节点错误率偏高
  * 细则
    * 11:20 进度&邮件&tapd
    * logreplay
      * 调试流水线
      * 第一批 20:43 1台
      * 第二批 21:07 
      * 第三批 21:26
      * 第四批 21:52
      * 第五批 22:38
    * 插件
    * 其他
      * 报销
      * 剖析&反馈
      * 反思工作
      * 方法论
  * 12/09
    * 总结：
      * 插件
        * 协助排查压测
        * 调大rpop频率
        * 整理初期上云的redis信息
    * 细则
      * 11:20 进度&邮件&tapd
      * 插件
        * 上云
          * index  think_xia
          * 画像 eric
          * 召回 打散 yibinxu
          * ranking tavonmeng
      * 其他
        * 报销-滴滴、居住证
        * 剖析&反馈、反思工作、方法论
  * 12/10
    * 总结：
      * 插件
        * 确认曝光前缀相关算法、双写多久、开始双写时间
        * 其他redis申请中，待确认
    * 细则
      * 11:20 进度&邮件&tapd
      * 插件
        * debug
          * 无量配置问题导致基线消费不动
        * 上云
          * 已和eric确认双写2天，具体开始时间待定；已和shuomeng确认前缀双写1天，12月11日开始双写
          * index  think_xia
          * 画像 eric
          * 召回 打散 yibinxu
          * ranking tavonmeng
      * 其他
        * 报销-滴滴、居住证
        * 剖析&反馈、反思工作、方法论

## week 53

* 上周工作
  * logreplay
    * 周二使用一个发布走了一遍全流程，已上线，后续粗排使用新流水线发布
  * 插件
    * 协助排查压测消费不动的问题
      * istore下线proxy后不断开连接，导致卡死——honghaobao加超时，并切换回旧redis
      * 无量配置错误导致基线消费不动
    * redis上云
      * 先迁移5个redis。申请中，并确认曝光redis的双写，其他redis待确认
* 12/13
  * 总结：
    * 插件
      * 监控：代码开发完，明日压测
      * redis上云：第一批已全开式双写，明日确认离线diff；在线代码调试中
  * 细则
    * 11:20 进度&邮件&tapd
    * 插件
      * 上云
        * 子账号上限导致有个申请需要重试。
        * 曝光redis已推动eric进行双写，之后给离线diff；shuomeng已经开始双写，晚点给出离线diff
        * 艹，多申请了1T。后续再找个要上云的redis加到这个批次里
      * 监控
        * 代码开发完，明日压测两次
    * 其他
      * 报销-滴滴、居住证
      * 剖析&反馈、反思工作、方法论
      * 答辩ppt、代码
* 12/14
  * 总结：
    * 插件
      * 监控：打点已上线，后续调一下脚本
      * redis上云：第一批开始双写，有几个漏掉的未迁。已起小包实验
  * 细则
    * 11:00 进度&邮件&tapd
    * 插件
      * 上云
      * 监控
    * 其他
      * 报销-滴滴、居住证
      * 剖析&反馈、反思工作、方法论
      * 答辩ppt、代码
* 12/15
  * 总结：
    * 插件
      * redis上云：
        * 第一批中3个合入combo——晚上combo压测翻车，明日待查
        * 有一个双写的还没改完
        * 开始询问第二批负责人，4/9
        * 晚上脚本问题差点导致出事故
      * 监控
  * 细则
    * 11:00 进度&邮件&tapd
    * 插件
      * 上云
      * 监控
    * 其他
      * 报销-滴滴、居住证
      * 剖析&反馈、反思工作、方法论
      * 答辩ppt、代码
* 12/16
  * 总结：
    * 插件
      * redis上云：
        * CL5翻车，改了之后重新起了个小包实验
      * 监控
        * 性能调整移交给国庆
  * 细则
    * 11:00 进度&邮件&tapd
    * 插件
      * 上云：combo1215翻车
        * dhf_debug_base_.74912_d22eb66_202112162249 ——复现——有我的改动
        * dhf_debug_nocl5.74911_9dfdf70_202112162250——解决
        * cl5调用的问题
      * 监控
        * 性能调整移交给国庆
    * 其他
      * 报销-滴滴、居住证
      * 剖析&反馈、反思工作、方法论
      * 答辩ppt、代码
* 12/17
  * 总结：
    * 插件
      * redis上云：
        * 申请机器，第二批开始推动双写
  * 细则
    * 11:00 进度&邮件&tapd
    * 插件
      * 上云：combo1215翻车
        * 切换mq redis
        * 确认下修改cl5后的效果
        * 推动双写
          * 机器已全部申请下来，双写确认中
    * 其他
      * ~~报销-滴滴~~、居住证
      * 剖析&反馈、反思工作、方法论
      * 答辩ppt、代码

## week 54

* 本周工作:

  *  完善trigger监控，记录到redis：polaris维度已上线；expid维度会对吞吐有影响，需优化（@kangnie(聂国庆) 后续跟进）
  *  redis上云：
    * 第一批中：1个trigger使用的已经上线；另外3个rs使用的，已通过combo全量压测。待随combo推全；
    * 第二批已申请到资源，并开始推动双写

* 下周计划：

  * push重构：基建类开发
  *  redis上云：第二批

* 12/20

  * 总结：
    * 插件
      * redis上云：trigger上周改动导致小包实验会打到基线，fix后需再观察下我的小包和combo小包实验效果
    * push-代码融合
      * 阅读代码，准备开始
  * 细则
    * 11:00 进度&邮件&tapd
    * 插件
    * 其他
      * 居住证
      * 剖析&反馈、反思工作、方法论
      * 答辩ppt、代码

* 12/21

  * 总结：
    * 插件
      * redis上云
        * 小包实验不平，combo中revert，另外我自己的小包去掉了其他人的代码再看看
    * push-代码融合
      * register 提 MR
  * 细则
    * 11:00 进度&邮件&tapd
    * 插件
      * redis上云
    * 其他
      * 居住证
      * 剖析&反馈、反思工作、方法论
      * 答辩ppt、代码

* 12/22

  * 总结：

    * 插件
      * redis上云
    * push-代码融合
      * context类

  * 细则

    * 11:00 进度&邮件&tapd

    * 插件

      * redis上云

      * 实验不平，再多做几个小包实验看看

      * | tag               | 改动 | 小包          | 小流量环境  |
        | ----------------- | ---- | ------------- | ----------- |
        | dhf_redis_1_a     | 曝光 | Pkg_42,pkg_45 | 35          |
        | dhf_redis_1_b     |      | Pkg49,pkg46   | 34          |
        | dhf_redis_1_3     |      | Pkg18,pkg19   | 36          |
        | dhf_redis_1_merge |      | Xae,xab       | Hongfendong |

        监控

        * kangnie压测已过，留到线上

    * push代码融合

      * Context

    * 其他

      * 居住证
      * 剖析&反馈、反思工作、方法论
      * 答辩ppt、代码

* 12/23

  * 总结：

    * 插件
      * redis上云
    * push-代码融合
      * context类

  * 细则

    * 11:00 进度&邮件&tapd

    * 插件

      * redis上云

      * 实验不平，再多做几个小包实验看看

      * | tag               | 改动 | 小包              | 小流量环境  | 备注         |
        | ----------------- | ---- | ----------------- | ----------- | ------------ |
        | dhf_redis_1_a     | 曝光 | **Pkg_42**,pkg_45 | 35          | 有问题，负向 |
        | dhf_redis_1_b     |      | **Pkg49**,pkg46   | 34          | ok           |
        | dhf_redis_1_3     |      | Pkg18,**pkg19**   | 36          | Ok           |
        | dhf_redis_1_merge |      | Xae,xab           | Hongfendong |              |

        

    * push代码融合

      * Context

    * 答辩代码准备

      * user_scorer: .h 152/320, .cpp  872/1314
      * Redis_cache: 
        * 旧 .h 135/169,  .cpp 179/191 ,   87.22%
          * https://git.woa.com/qqnews_rec/astra/merge_requests/36/commits
          * 下的a1ba6414b61a1b52d35ed98d914b69ef82b8cd98
        * 新 .h 147/201 .cpp 227/245  83.86%
        * .h 26/201 .cpp 69/245 21.30%
        * 说明：
          * redis_cache.h/.cpp重新提交了下。主要当时是先合入到其他同学分支，再从这个分支合入master的，因此归属到了其他同学名下，git blame的行数只有 21%（95/446）与我有关。
          * 可查阅[3月的MR](https://git.woa.com/qqnews_rec/astra/merge_requests/36/commits)，其中包含的提交a1ba6414b61a1b52d35ed98d914b69ef82b8cd98下的文件状态（当时路径为score/item_scorer/item_scorer.h和score/item_scorer/item_scorer.cpp）。git blame与我相关行数87%（314/360）
          * 重新提交后，git blame相关行数为84%（374/446）

    * 其他

      * 居住证
      * 剖析&反馈、反思工作、方法论
      * 答辩ppt、代码

* 12/24

  * 总结：

    * 插件
      * redis上云
    * push-代码融合
      * context类

  * 细则

    * 11:00 进度&邮件&tapd

    * 插件

      * redis上云

      * 实验不平，再多做几个小包实验看看

      * | tag               | 改动 | 小包              | 小流量环境  | 备注         |
        | ----------------- | ---- | ----------------- | ----------- | ------------ |
        | dhf_redis_1_a     | 曝光 | **Pkg_42**,pkg_45 | 35          | 有问题，负向 |
        | dhf_redis_1_b     |      | **Pkg49**,pkg46   | 34          |              |
        | dhf_redis_1_3     |      | Pkg18,**pkg19**   | 36          | 昨日02Ok     |
        | dhf_redis_1_merge |      | Xae,xab           | Hongfendong |              |

        | tag           | redis                                        | 小流量环境  | 备注     |
        | ------------- | -------------------------------------------- | ----------- | -------- |
        | dhf_redis_1_a |                                              | 35          | 负向显著 |
        | dhf_redis_1_b |                                              | 34          | 不显著   |
        | dhf_redis_1_3 | Pkg18,**pkg19**                              | 36          | 不显著   |
        | Dhf_redis_1_4 | all.wxplugin_user_history.redis.com          | 18          | 不显著   |
        | dhf_redis_2_1 | all.news_plugin_dislike_info.redis.com       | 21          | 不显著   |
        | dhf_redis_2_2 | trpc.gz7890.wxplugin_featurereduce.redis.com | hongfendong | 不显著   |

        

    * push代码融合

      * Context

    * 其他

      * 居住证
      * 剖析&反馈、反思工作、方法论
      * 答辩ppt、代码

## week 55

* 上周工作：

  * redis上云：tab起了5个redis，1个显著负向待查，另外4个不显著，可以合combo
  * push-插件融合：开发反射类、context
  * 整理答辩代码

* 12/27

  * 总结：

    * 插件

      * redis上云

      * | tag           | redis                                        | 小流量环境  | 备注                              |
        | ------------- | -------------------------------------------- | ----------- | --------------------------------- |
        | dhf_redis_1_a |                                              | 35          | 负向显著<br />——3日数据转为不显著 |
        | dhf_redis_1_b |                                              | 34          | 不显著--已combo                   |
        | dhf_redis_1_3 | Pkg18,**pkg19**                              | 36          | 不显著--已combo                   |
        | Dhf_redis_1_4 | all.wxplugin_user_history.redis.com          | 18          | 不显著--已combo                   |
        | dhf_redis_2_1 | all.news_plugin_dislike_info.redis.com       | 21          | 不显著                            |
        | dhf_redis_2_2 | trpc.gz7890.wxplugin_featurereduce.redis.com | hongfendong | 不显著                            |

    * push-代码融合

      * 封装init

  * 细则

    * 11:00 进度&邮件&tapd

    * 插件

      * redis上云

        * | tag             | redis                              | 小流量环境  | 备注 |
          | --------------- | ---------------------------------- | ----------- | ---- |
          | dhf_redis_1_a   |                                    | 35          |      |
          | dhf_redis_2_3   | all.wxp_rerank_simfilter.redis.com | 34          |      |
          | dhf_redis_2_4   |                                    | 18          |      |
          | dhf_redis_2_5   |                                    | 21          |      |
          | dhf_redis_2_6   |                                    | 36          |      |
          | redis_1_a_debug |                                    | Hongfendong |      |

    * push代码融合

      * 有不少代码需要调整

    * 其他

      * 居住证
      * 剖析&反馈、反思工作、方法论
      * 答辩ppt
  
* 12/28

  * 总结：

    * 插件-redis上云

      * 第二批中部分前缀无需双写，已下线
    * push-代码融合
  
      * 调试init
  
  * 细则
  
    * 11:00 进度&邮件&tapd
  
    * 插件

      * redis上云

        * | tag             | redis                              | 小流量环境  | 备注                               |
          | --------------- | ---------------------------------- | ----------- | ---------------------------------- |
          | dhf_redis_1_a   |                                    | 35          | 继续观察，批次1中3日数据转为不显著 |
          | dhf_redis_2_3   | all.wxp_rerank_simfilter.redis.com | 34          |                                    |
          | dhf_redis_2_4   |                                    | 18          |                                    |
          | dhf_redis_2_5   |                                    | 21          |                                    |
          | dhf_redis_2_6   |                                    | 36          |                                    |
          | redis_1_a_debug |                                    | Hongfendong |                                    |
  
    * 其他
  
      * 居住证
      * 剖析&反馈、反思工作、方法论
      * 答辩ppt
  
* 12/29

  * 总结：

    * 插件-redis上云
      * 第二批4个已合29日combo
      * 曝光redis依然抖动中，继续观察
    * push-代码融合
      * Init完成 Experiment、index、recall
  
  * 细则
  
    * 11:00 进度&邮件&tapd
  
    * 插件
  
      * redis上云
  
        * | tag             | redis                              | 小流量环境  | 备注                                                         |
          | --------------- | ---------------------------------- | ----------- | ------------------------------------------------------------ |
          | dhf_redis_1_a   |                                    | 35          | 继续观察，批次1中3日数据转为不显著<br />实验2中首日数据负向显著 |
          | dhf_redis_2_3   | all.wxp_rerank_simfilter.redis.com | 34          | 不显著，已合29日combo                                        |
          | dhf_redis_2_4   |                                    | 18          | 不显著，已合29日combo                                        |
          | dhf_redis_2_5   |                                    | 21          | 不显著，已合29日combo                                        |
          | dhf_redis_2_6   |                                    | 36          | 不显著，已合29日combo                                        |
          | redis_1_a_debug |                                    | Hongfendong | 实验2中首日数据负向显著                                      |

    * 其他

      * 居住证
      * 剖析&反馈、反思工作、方法论
      * 答辩ppt
  
* 12/30

  * 总结：

    * 插件-redis上云
      * 曝光redis肯定有问题，想办法起个实验
    * push-代码融合
      * Init完成 ranking、rerank、period
  
  * 细则
  
    * 11:00 进度&邮件&tapd
  
    * 插件
  
      * redis上云

        * | tag             | redis                              | 小流量环境  | 备注                                                        |
          | --------------- | ---------------------------------- | ----------- | ----------------------------------------------------------- |
          | dhf_redis_1_a   |                                    | 35          | 继续观察，批次1中3日数据转为不显著<br />实验2中数据负向显著 |
          | dhf_redis_2_3   | all.wxp_rerank_simfilter.redis.com | 34          | 不显著，已合29日combo                                       |
          | dhf_redis_2_4   |                                    | 18          | 不显著，已合29日combo                                       |
          | dhf_redis_2_5   |                                    | 21          | 不显著，已合29日combo                                       |
          | dhf_redis_2_6   |                                    | 36          | 不显著，已合29日combo                                       |
          | redis_1_a_debug |                                    | Hongfendong | 实验2中数据负向显著                                         |
  
    * 其他
  
      * 居住证
      * 剖析&反馈、反思工作、方法论
      * 答辩ppt

* 12/31

  * 总结：
    * 插件-redis上云
      * 曝光redis肯定有问题，想办法起个实验
    * push-代码融合
      * Init完成periodic task，并解决index的core——push和插件各有一份代码(AB vs ab)，平迁过来没匹配上(Ab)

  * 细则

    * 10:00 进度&邮件&tapd

    * 插件

      * redis上云

        * | tag           | redis | 小流量环境  | 备注                                                        |
          | ------------- | ----- | ----------- | ----------------------------------------------------------- |
          | dhf_redis_1_a |       | 35          | 继续观察，批次1中3日数据转为不显著<br />实验2中数据负向显著 |
          | Redis_1_a_11  |       | 34          | 已部署                                                      |
          | redis_1_a_12  |       | 18          | 已部署                                                      |
          | Redis_1_a_13  |       | 21          | 已部署                                                      |
          | redis_1_a_14  |       | 36          | 已部署                                                      |
          | Redis_3_1     |       | Hongfendong | 已部署                                                      |

    * 其他

      * 居住证
      * 剖析&反馈、反思工作、方法论
      * 答辩ppt



* logreplay
  * 录制环境 http://testone.woa.com/logreplay/b-a7da6065-5eed-3811-990d-dcb3ee6c15b1#/13657b8bf4974c8784d9dc77163e648d/module/detail/b523bfd733894604a1a8021aed7fe16a/record
  * gor流水线 http://devops.oa.com/console/pipeline/rcm2/p-4136432c983f42059fd7a244958ae64d/history 



* 插件升级

  * curl -d '{"trace_id":"", "data":[{"wxopenid" :"o04IBACPJkN-cAPMnt8cUQFoqUEQ","conf":"{\"exp\":\"tab\"}"}]}' http://127.0.0.1:10284/RecommendService/GetPolaris

  * 

    ```
    # item
    grep "item < 4" log.log |awk '0!= $10 {print $10, $11}'
    cd ~/code/log/ && grep 'item < 4' log.log |awk '{print $10, $11 } '|wc -l && grep 'response code:' log.log |wc -l
    
    #
    grep wxopen log.log |awk '{a += $NF}END{print a}'
    grep wxopen log.log |awk '{a[$(NF-1)] += $NF; b[$(NF-1)] += 1}END{for(i in a){print i ,a[i],b[i], a[i]/b[i]}}'
    
    
     grep "trigger com" log.log |awk '{a[$(NF-1)] += $NF;s += $NF}END{for(i in a){print i ,a[i]}; print s}'
    
    grep GetRecommen_ log.log |awk '{a[$(NF-2),":",$6] += 1}END{for(i in a) {s += a[i];print i, a[i]};print s}'
    ##
    curl -H "Content-Type: application/json" -d '{"trace_id":"77889900", "data":[{"wxopenid":"o04IBAH9x3-RAnp6QZNFMNXr9D2U","conf":"{\"exp\":\"tab\",\"city_tier\":\"3\"}"}]}' http://9.56.10.49:13134/trpc.news_rs.recommend_server_trpc.HttpRecommendService/Recommend | python2 -mjson.tool
    
    curl -H "Content-Type: application/json" -d '{"trace_id":"77889900", "data":[{"wxopenid":"o04IBAND0KZInicfx1xar8GRiX0w","conf":"{\"exp\":\"itemPoolwx\",\"city_tier\":\"2\"}"}]}' http://11.181.82.57:13154/trpc.news_rs.recommend_server_trpc.HttpRecommendService/Recommend | python2 -mjson.tool
    
    #### universe
    curl -H "Content-Type: application/json" -d '{"trace_id":"77889900", "data":[{"wxopenid":"o04IBAND0KZInicfx1xar8GRiX0w","conf":"{\"exp\":\"itemPoolwx\",\"city_tier\":\"2\"}"}]}' http://11.181.82.57:13154/trpc.news_rs.recommend_trpc_universe.HttpRecommendService/Recommend | python2 -mjson.tool
    ##trpc
    curl  -H "Content-Type: application/json"   -d '{"trace_id":"", "data":[{"wxopenid" :"o04IBACPJkN-cAPMnt8cUQFoqUEQ","conf":"{\"exp\":\"tab\"}", "get_bucket_test_response":{"cache_version":"1635237435","version":"TAB_CPP_SDK_1.1.6","depths":{"1":1},"m_bucket_test":{"exp_tfasdf":{"s_bucket_test_id":"100000","params":{},"buckets":[],"i_bucket":0,"group_key_":"exp_tfasdf","strategy_type_":"default","exp_key_":"default","is_allow_list_":0},"wxp_cp_00":{"s_bucket_test_id":"100000","params":{},"buckets":[],"i_bucket":0,"group_key_":"wxp_cp_keep_20210707","strategy_type_":"default","exp_key_":"default","is_allow_list_":0},"content_safe_control_1":{"s_bucket_test_id":"100000","params":{},"buckets":[],"i_bucket":0,"group_key_":"content_safe_exp_first_default","strategy_type_":"default","exp_key_":"default","is_allow_list_":0},"rerank_0":{"s_bucket_test_id":"100000","params":{},"buckets":[],"i_bucket":0,"group_key_":"exp_diaoxing_low_middle_1026","strategy_type_":"default","exp_key_":"default","is_allow_list_":0},"app_new_user":{"s_bucket_test_id":"100000","params":{},"buckets":[],"i_bucket":0,"group_key_":"new_user_Installation_package_copy","strategy_type_":"default","exp_key_":"default","is_allow_list_":0},"numerous_rank_layer":{"s_bucket_test_id":"2721486","params":{},"buckets":[],"i_bucket":3605,"group_key_":"exp_feature_cut_model_0928_copy","strategy_type_":"control","exp_key_":"exp_feature_cut_model_0927_A","is_allow_list_":0},"wxplugin_exp_level1":{"s_bucket_test_id":"100000","params":{},"buckets":[],"i_bucket":0,"group_key_":"exp_wxplugin_ads_test","strategy_type_":"default","exp_key_":"default","is_allow_list_":0},"recall_exps":{"s_bucket_test_id":"100000","params":{},"buckets":[],"i_bucket":0,"group_key_":"exp_news_wxp_dssm_u2i_sample","strategy_type_":"default","exp_key_":"default","is_allow_list_":0},"single_layer":{"s_bucket_test_id":"2805241","params":{"polaris":"trpc.normal.hongfendong_base.wxplugin_rs.main_port"},"buckets":[],"i_bucket":62,"group_key_":"exp_news_wxp_testSplitFlow","strategy_type_":"control","exp_key_":"exp_news_wxp_testSplitFlow_A","is_allow_list_":1}}}}]}' http://9.44.131.241:11045/trpc.news_rs.recommend_server_trpc.HttpRecommendService/Recommend
    
    ## brpc
    curl -d '{"trace_id":"", "data":[{"wxopenid" :"o04IBACPJkN-cAPMnt8cUQFoqUEQ","conf":"{\"exp\":\"tab\"}"}]}' http://9.37.8.39:11069/RecommendService/GetPolaris
    
    curl -d '{"trace_id":"","data":[{"wxopenid":"o04IBACPJkN-cAPMnt8cUQFoqUEQ","conf":"{\"exp\":\"tab\"}","get_bucket_test_response":{"cache_version":"1634562787","version":"TAB_CPP_SDK_1.1.5.2","depths":[{"key":1,"value":1}],"m_bucket_test":{"app_new_user":{"s_bucket_test_id":"100000","i_bucket":0,"group_key_":"new_user_Installation_package_copy","strategy_type_":"default","exp_key_":"default","is_allow_list_":0,"params":{}},"numerous_rank_layer":{"s_bucket_test_id":"2721486","i_bucket":3605,"group_key_":"exp_feature_cut_model_0928_copy","strategy_type_":"control","exp_key_":"exp_feature_cut_model_0927_A","is_allow_list_":0,"params":{}},"wxplugin_exp_level1":{"s_bucket_test_id":"100000","i_bucket":0,"group_key_":"exp_wxplugin_ads_test","strategy_type_":"default","exp_key_":"default","is_allow_list_":0,"params":{}},"sharepage_exp_level1":{"s_bucket_test_id":"100000","i_bucket":0,"group_key_":"sharepage_switch_platform","strategy_type_":"default","exp_key_":"default","is_allow_list_":0,"params":{}},"single_layer":{"s_bucket_test_id":"2805241","i_bucket":0,"group_key_":"exp_news_wxp_testSplitFlow","strategy_type_":"control","exp_key_":"exp_news_wxp_testSplitFlow_A","is_allow_list_":1,"params":{"polaris":"WangWangWang"}},"recall_exps":{"s_bucket_test_id":"100000","i_bucket":0,"group_key_":"exp_news_wxp_dssm_u2i_exp_active_copy","strategy_type_":"default","exp_key_":"default","is_allow_list_":0,"params":{}},"wxp_cp_00":{"s_bucket_test_id":"2367176","i_bucket":69431,"group_key_":"wxp_cp_keep_20210707","strategy_type_":"treatment","exp_key_":"wxp_cp_keep_20210707_C","is_allow_list_":0,"params":{"recall_config":"{\"topCP\":{\"max_num\":50}}","rerank_config":"{\"topI^Cge\":1,\"cpKeepNum\":1,\"cpKeepUpdate\":1,\"itemPool\":{\"thr_ctr_v\":0.1,\"thr_active_d\":15,\"thr_posid\":15}}"}},"exp_tfasdf":{"s_bucket_test_id":"100000","i_bucket":0,"group_key_":"exp_tfasdf","strategy_type_":"default","exp_key_":"default","is_allow_list_":0,"params":{}},"content_safe_control_1":{"s_bucket_test_id":"100000","i_bucket":0,"group_key_":"content_safe_exp_first_default","strategy_type_":"default","exp_key_":"default","is_allow_list_":0,"params":{}},"rerank_0":{"s_bucket_test_id":"100000","i_bucket":0,"group_key_":"exp_diaoxing_middle_high_active_scatter_1015","strategy_type_":"default","exp_key_":"default","is_allow_list_":0,"params":{}}}}}]}' http://127.0.0.1:10284/RecommendService/Recommend | python -mjson.tool
    ```

  * 

  * 16: 00会议

    * 现在的发布流程，开关项如何测的？
    * logreplay
      * 只能测完全相同的请求，新feature要人工diff；
      * 随机性、随机值、cache、set_time；
      * 会有多次、相同的下游请求么？
      * 代码有侵入性（无重复下游、透传server context、多环境路：测试、小流量环境）
    * 如何搭个测试环境，有没有什么坑，trpc配置用线上的？从哪copy流量
    * 痛点——节后给方案
      * 第一步，接入logreplay
      * 整个发布流程的规范——flags的组合？
      * 召回 detools脚本：开发机bin传到测试环境
      * 预发布环境、高中低用户按比例，抽10%。计算资源也按比例设计

* 切换模型：
  * user服务: trpc.Serving.RoughRankingUserFServerTF.PredictInterfaceObj
  * User model key: modelrecallgrp_new_fea_v2_senet.default
  * item服务仍使用线上服务
  * item前缀: pre_rank_902v3
* GetVideoProfileIndex函数删除：因为其行为和ranking不一致。已按照ranking的修改代码
* 写死了模型的一些参数参数：目前模型的target、password不是走实验配置，是写死在代码里的，但模型的前缀、model name是读实验配置。导致需要bin和配置强绑定。本次切换模型先写死，后续再调整、解绑。见 `astra/coarse_ranking/interface/coarse_ranking_context.h`中对`user_model_info`的改动
* 一些format改动
* 更新单测



* 机器使用

* * 3422f793.qqnews.coarse_ranking.tj100041  shuoyang

* 准备起实验
  * experiment_base2.coarse_ranking
  * experiment_test5.coarse_ranking
  * experiment_test4.coarse_ranking

* bazel build :coarse_ranking --define include_replay_logreplay=true --copt="-D LOGREPLAY_DEBUG_STDOUT"







* log replay：
  * 需要手动改配置文件：tracing -> replay
  * 需要用MakeClientContxt
  * diff   https://iwiki.woa.com/pages/viewpage.action?pageId=543187958
    * 可以添加白名单、黑名单
    * 数组：^to_rank_docinfo\[.*].coarse_ranking_score
    * 不要把logreplay的发布到线上，目前放弃了性能，以便更好的处理代码（copy临时对象）
    * 可能的坑
      * 排除随机性：cache、随机值
      * key需要有唯一性：对下游同一个服务的多次调用是否会是同一个key，这回导致回放时乱掉
        * 非模型召回 vs 模型召回的特征处理
        * predict_req.non_video 有可能 == predict_req.video
        * item redis可能是50个相同doc，分包后相同
  * 二期
    * 流量编辑
    * 请求级覆盖RBC
  * 平台机器
    * 11.181.81.0 深圳腾讯深宇DC3号楼0401
    * 9.146.142.2 深圳移动光明DC3号楼1103
    * 9.146.146.139 深圳移动光明DC3号楼1003
    * 9.223.245.252 深圳电信蛇口高科DC0403
    * 9.218.41.78 广州电信永顺DC2号楼2楼3202
    * 11.187.134.102 广州移动华新园ACG16栋6楼0602
    * 11.185.94.199 上海电信奉贤DC2号楼403
    * 11.185.81.95 上海电信奉贤DC2号楼402
  
  
  
* 多环境路由
  * 被调入流量规则 > 主调出流量规则



* 